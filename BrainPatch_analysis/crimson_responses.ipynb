{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crimson Stimulation Responses\n",
    "\n",
    "Looking through the BrainPatch stimulation responses, in particular those LFP/dendritic spikes. Need to figure out what they are...\n",
    "\n",
    "From the \"artifact_exploration\" stuff I was doing, it looks like I'll mostly need to look at clips around the stim. Can probably HPF at about 70 hz and keep the interesting stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from open_ephys.analysis import Session\n",
    "from scipy import signal\n",
    "# from scipy.fft import fft, fftfreq\n",
    "# from scipy.signal.windows import gaussian\n",
    "from sklearn.decomposition import PCA\n",
    "import os, glob, re\n",
    "import openephys_utils \n",
    "\n",
    "\n",
    "# %matplotlib ipympl\n",
    "%matplotlib qt\n",
    "\n",
    "# pdfPages for saving images to a multi-page PDF\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a few functions for later usage\n",
    "\n",
    "First one just opens an open ephys directory and returns the signals, timestamps, and events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_sig_events(directory:str):\n",
    "    # open up a session, then pull out the signal and events\n",
    "    session = Session(directory)\n",
    "\n",
    "    recording = session.recordnodes[0].recordings[0].continuous[0]\n",
    "\n",
    "    # get out the signal\n",
    "    sig = recording.samples[:,:64] * recording.metadata['bit_volts'][0]\n",
    "\n",
    "    # pull out the events -- both giving the time and the indices\n",
    "    events = np.argwhere(np.diff(recording.samples[:,64]>5000) == 1)\n",
    "    events = events.reshape([int(events.shape[0]/2),2])\n",
    "    event_ts = events/recording.metadata['sample_rate']\n",
    "\n",
    "    # timestamps\n",
    "    timestamps = recording.sample_numbers - recording.sample_numbers[0]\n",
    "    timestamps = timestamps/recording.metadata['sample_rate']\n",
    "\n",
    "    return sig, timestamps, events, event_ts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to find the minimum of a clipped period after the stimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_responses(sig, events, len_ms:int = 25, n_chans:int = 64, sample_rate:int = 30000):\n",
    "\n",
    "    t_len = len_ms*30 # 52 ms * 30 khz\n",
    "\n",
    "    # set up the events to plot patches\n",
    "    n_events = events.shape[0] # number of stimulation events\n",
    "\n",
    "    responses = np.zeros((n_events, t_len, n_chans))\n",
    "    # maxs = np.zeros((n_events, n_chans)) # not getting much info from these\n",
    "    # rel_maxs = np.zeros((n_events, n_chans))\n",
    "    # abs_maxs = np.zeros((n_events, n_chans))\n",
    "    mins = np.zeros((n_events, n_chans))\n",
    "    rel_mins = np.zeros((n_events, n_chans))\n",
    "    abs_mins = np.zeros((n_events, n_chans))\n",
    "\n",
    "    for i_event, event in enumerate(events):\n",
    "        response = sig[event[0]:event[0]+len_ms*int(sample_rate/1000),:]\n",
    "        means = np.mean(sig[event[0]+4:event[1]-4,:], axis = 0)\n",
    "        responses[i_event,:,:] = response - means # response for each channel\n",
    "    \n",
    "        mins[i_event,:] = np.min(response - means, axis=0)\n",
    "        rel_mins[i_event,:] = np.argmin(response - means, axis=0)/30000\n",
    "        abs_mins[i_event,:] = rel_mins[i_event,:] + event_ts[i_event,0]\n",
    "\n",
    "    return mins, rel_mins, abs_mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the average post-stim responses for a particular channel. Will plot it into an existing axis if provided one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_avg_response(sig, events, len_ms:int = 25, channel = 0, ax:plt.axes=None, label:str=None):\n",
    "    # Plot the average response for a particular channel\n",
    "    \n",
    "    if ax is None:\n",
    "        fig,ax = plt.subplots()\n",
    "    \n",
    "    if label == None:\n",
    "        label = f'Channel {channel}'\n",
    "\n",
    "\n",
    "    # set up the events to plot patches\n",
    "    n_events = events.shape[0] # number of stimulation events\n",
    "\n",
    "    # put together a NxT array\n",
    "    t_len = len_ms * 30\n",
    "    responses = np.zeros((n_events, t_len))\n",
    "    \n",
    "    # go through each event\n",
    "    for i_event, event in enumerate(events):\n",
    "        response = sig[event[0]:event[0]+len_ms*30,channel]\n",
    "        means = np.mean(sig[event[0]+4:event[1]-4]) # center the during-stimulation to 0\n",
    "        responses[i_event,:] = response - means\n",
    "    \n",
    "    # put together the means, STDs, and timestamps\n",
    "    ts = np.arange(t_len)/30\n",
    "    means = np.mean(responses, axis=0)\n",
    "    line = ax.plot(ts, means, label=label)\n",
    "    \n",
    "    ts_std = np.ravel(np.array([ts, ts[::-1]]))\n",
    "    std = np.ravel(np.array([means + np.std(responses, axis=0), means[::-1] - np.std(responses, axis=0)[::-1]]))\n",
    "    patch_array = np.array([ts_std, std]).T\n",
    "    std_patch = Polygon(patch_array, alpha=0.2, color=line[-1].get_color())\n",
    "    ax.add_patch(std_patch)\n",
    "\n",
    "    # print(dir(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find spikes using the old-school default:\n",
    "\n",
    "1. Filter and de-mean\n",
    "1. Calculate a threshold: -4.5x the STD\n",
    "1. Flag issues:\n",
    "    1. Too-short ISIs (< 3 ms?)\n",
    "    1. Simulataneous-ish (on more than N channels)\n",
    "    1. Something about the wave shape -- deviations? Depth of field?\n",
    "1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_spikes(sig, filter_high:float = 6000, filter_low:float = 150, sample_rate:int = 30000, CAR:bool = True):\n",
    "    # number of channels\n",
    "    n_chan = np.min(sig.shape)\n",
    "    axis = np.argmax(sig.shape)\n",
    "    sig = sig.T if axis == 1 else sig # make sure that Time is along axis 0\n",
    "\n",
    "    # # CAR\n",
    "    # if CAR:\n",
    "    #     pca = PCA()\n",
    "    #     xform = PCA.fit_transform(sig)\n",
    "    #     # sig = np.matmul(xform, PCA.)\n",
    "\n",
    "\n",
    "    # filter the thing\n",
    "    sos = signal.butter(N=8, Wn=[filter_low, filter_high], fs=sample_rate, output='sos', btype='bandpass')\n",
    "    filt_sig = signal.sosfiltfilt(sos=sos, x=sig, axis=0)\n",
    "\n",
    "    # find a threshold for each channel\n",
    "    thresholds = np.expand_dims(-4.5 * np.std(filt_sig, axis=0), axis=0)\n",
    "\n",
    "\n",
    "    # find the crossings\n",
    "    thresholds_rep = np.tile(thresholds, (sig.shape[0], 1)) # create a TxN array of N threshold values\n",
    "    crossings = np.argwhere(np.diff((filt_sig<thresholds_rep).astype(int), axis=0) < 0)\n",
    "\n",
    "    # Create a dataframe for the spikes, and also store chunks of 50 ms of data\n",
    "    spike_df = pd.DataFrame({'sample_no':crossings[:,0].astype(int), 'electrode':crossings[:,1].astype(int)})\n",
    "    sample_columns = [f'sample {i - 10}' for i in range(50)]\n",
    "    spike_df.loc[:,sample_columns] = np.nan\n",
    "\n",
    "    for i_row,row in spike_df.iterrows():\n",
    "        spike_df.loc[i_row,sample_columns] = filt_sig[row['sample_no']-10:row['sample_no']+40,row['electrode']]\n",
    "\n",
    "    # return spike_df, filt_sig\n",
    "    return spike_df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single file analysis\n",
    "\n",
    "Mostly to check the functioning of the code when I'm batch processing files\n",
    "\n",
    "pull in the data -- we'll start with one file at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'Z:\\\\BrainPatch\\\\20241002\\\\lateral\\\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um'\n",
    "\n",
    "# load signals if we haven't already loaded it\n",
    "if 'sig' not in locals():\n",
    "    sig, timestamps, events, event_ts = open_sig_events(directory)\n",
    "\n",
    "# pull out the spikes\n",
    "if 'spike_df' not in locals():\n",
    "    spike_df,filt_sig = find_spikes(sig)\n",
    "\n",
    "# choose the channels to show\n",
    "channels = np.arange(40,50)\n",
    "\n",
    "# plot the continuous and show the times\n",
    "fig_cont, ax_cont = plt.subplots(nrows = len(channels), sharex=True)\n",
    "\n",
    "for i_channel, channel in enumerate(channels):\n",
    "    ax_cont[i_channel].plot(timestamps, filt_sig[:,channel])\n",
    "    for i_spike, spike in spike_df.loc[spike_df['electrode'] == channel].iterrows():\n",
    "        ax_cont[i_channel].axvspan((int(spike['sample_no'])-10)/30000, (int(spike['sample_no'])+40)/30000, color = 'cyan')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_spike_counts(spike_dict:dict, max_ts:int = None, min_ts:int = None, fs:int = 30000, bin_ms:float = .005):\n",
    "    # calculate the binned firing rates and return, along with bin timestamps\n",
    "\n",
    "    if (max_ts is None) or (min_ts is None):\n",
    "        print('Calculating bin range start and finish is a bummer! . Next time give me some info!')\n",
    "        max_ts,min_ts = 0,0\n",
    "        for chan_xings in spike_dict.values():\n",
    "            max_ts = int(max(max_ts, chan_xings['spike_ts'].max()))\n",
    "            min_ts = int(min(min_ts, chan_xings['spike_ts'].min()))\n",
    "        \n",
    "\n",
    "    bins = np.arange(start=min_ts, step = int(fs*bin_ms), stop=max_ts+1) # put together the bins\n",
    "    spike_counts = np.empty((len(bins),len(spike_dict.keys()))) # put together a pre-allocated array\n",
    "    for channel, data in spike_dict.items(): # loop through the dict\n",
    "        spike_counts[:,channel] = np.histogram(data['sample_no'], bins) # bin it\n",
    "\n",
    "\n",
    "    return spike_counts, bins    \n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('h')\n",
    "\n",
    "max_ts= int(sig.shape[0]) + 1\n",
    "min_ts= 0\n",
    "fs = 30000\n",
    "bin_ms = .005\n",
    "\n",
    "\n",
    "bins = np.arange(start=min_ts, step = int(fs*bin_ms), stop=max_ts+1) # put together the bins\n",
    "spike_counts = np.empty((len(bins)-1,len(spikes.keys()))) # put together a pre-allocated array\n",
    "for channel, data in spikes.items(): # loop through the dict\n",
    "    spike_counts[:,channel],_ = np.histogram(data['sample_no'], bins) # bin it\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openephys_utils\n",
    "# fig_pca, ax_pca = plt.subplots(nrows=4, sharex=True)\n",
    "directory = 'Z:\\\\BrainPatch\\\\20241002\\\\lateral\\\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um'\n",
    "\n",
    "if not all([var in locals() for var in ['sig', 'timestamps', 'events', 'events_ts']]):\n",
    "    sig, timestamps, events, event_ts = openephys_utils.open_sig_stims(directory)\n",
    "\n",
    "sig_eraasr = openephys_utils.ERAASR(sig)\n",
    "sig_mine = openephys_utils.ERAASR(sig, mode='mine')\n",
    "\n",
    "# spikes = openephys_utils.threshold_crossings(sig_eraasr)\n",
    "spike_dict = openephys_utils.threshold_crossings(sig_eraasr, multi_rejection=None)\n",
    "fr,fr_ts = openephys_utils.calc_FR(spike_dict, max_samp = sig.shape[0], min_samp=0, bin_ms = 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_stim_FR(firing_rate:np.array, stims:np.array, bin_sec:float = .001, normalize:bool = True, resp_length_samp:int = 12000, fs:int=30000):\n",
    "    '''\n",
    "    the average firing rate for a recording (per channel) for each recording setup\n",
    "    \n",
    "    inputs:\n",
    "        firing_rate: np.array               - array of the firing rates\n",
    "        stims:np.array                      - stimulation start and stop times (Nx2) \n",
    "        normalize:bool                      - Should we normalize so the average (pre-stim) firing rate is 1?\n",
    "        fs:int                              - sample rate (Hz) [30000]\n",
    "        bin_sec:float                         - bin window length (s) [.001]\n",
    "        bin_ms:int\n",
    "        resp_length_samp:int                - length of interest for response (samples) [15000]\n",
    "\n",
    "        \n",
    "    outputs:\n",
    "        avg_fr:np.array            - \n",
    "        std_fr:np.array\n",
    "    \n",
    "    '''\n",
    "    # convert bin_win (seconds) into a sample value\n",
    "    bin_samp = int(fs*bin_win)\n",
    "\n",
    "    # normalize off the average firing rates before the first stim:\n",
    "    if normalize:\n",
    "        pre_stim = firing_rate[:stims[0,0], :] # pull out the firing rates before the first stimulation\n",
    "        firing_rate = np.matmul(firing_rate, np.linalg.pinv(pre_stim.mean(axis=0)*np.eye(firing_rate.shape[1]))) \n",
    "\n",
    "    # pull out the stimulation segments, then reshape\n",
    "    stim_resp = firing_rate[(np.concatenate([np.arange(start=int(row[0]/bin_samp), stop=int((row[0]+resp_length_samp)/bin_samp)) for row in stims])).astype(int), :] \n",
    "    stim_resp = stim_resp.reshape((stims.shape[0],int(resp_length_samp/bin_samp),64)).transpose((1,0,2))\n",
    "    \n",
    "    # then pull out the mean for each channel and the std\n",
    "    avg_fr = stim_resp.mean(axis=1) # mean across trials\n",
    "    std_fr = stim_resp.std(axis=1) # standard deviation across trials\n",
    "\n",
    "    return avg_fr, std_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_FR(mean_FR:np.array, stims:np.array, std_FR:np.array = None, channel:int = None, ax:plt.axes = None):\n",
    "    '''\n",
    "    Plot the mean firing rates for a specific channel. \n",
    "\n",
    "    inputs:\n",
    "        mean_FR : np.array\n",
    "        stims : np.array\n",
    "        std_FR : np.array\n",
    "        channel : int\n",
    "        ax : matplotlib axes\n",
    "\n",
    "    outputs:\n",
    "    '''\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    \n",
    "    FR_line = ax.plot(mean_FR[:,channel])\n",
    "    if std_FR is not None:\n",
    "        ts = np.arange(mean_FR.shape[0])\n",
    "        ts_std = np.ravel(np.array([ts, ts[::-1]]))\n",
    "        std_patch = np.concatenate([mean_FR[:,channel] + std_FR[:,channel], np.maximum(mean_FR[:,channel][::-1] - std_FR[:,channel][::-1],0)])\n",
    "        std_patch = Polygon(np.array(list(zip(ts_std,std_patch))), color=FR_line[0].get_color(), alpha=0.2)\n",
    "        ax.add_patch(std_patch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_fr,std_fr = avg_stim_FR(fr, events, normalize=False)\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "plot_mean_FR(mean_fr, events, std_fr, 51, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_length = 12000\n",
    "channel=51\n",
    "fs = 30000\n",
    "bin_win = .001\n",
    "bin_samp = int(fs*bin_win)\n",
    "resp_samp = int(resp_length/bin_samp)\n",
    "\n",
    "stim_resp = fr[(np.concatenate([np.arange(start=int(row[0]/bin_samp), stop=int((row[0]+resp_length)/bin_samp)) for row in events])).astype(int),:]\n",
    "stim_resp = stim_resp.reshape((events.shape[0],resp_samp,64)).transpose((1,0,2))\n",
    "\n",
    "fig,ax = plt.subplots(nrows=3, sharex=True, sharey=True)\n",
    "for i_event in np.arange(events.shape[0]):\n",
    "    ax[0].plot(np.arange(resp_samp)*bin_samp, stim_resp[:,i_event,channel])\n",
    "ax[1].plot(np.arange(resp_samp)*bin_samp, stim_resp[:,:,channel].mean(axis=1))\n",
    "ax[1].plot(np.arange(resp_samp)*bin_samp, stim_resp[:,:,channel].mean(axis=1) + stim_resp[:,:,channel].std(axis=1))\n",
    "ax[1].plot(np.arange(resp_samp)*bin_samp, stim_resp[:,:,channel].mean(axis=1) - stim_resp[:,:,channel].std(axis=1))\n",
    "openephys_utils.plot_PSTH(spike_dict, events, channel, ax=ax[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_stim = fr[:int(events[0,0]/bin_samp),:]\n",
    "avg_prestim = np.linalg.pinv(pre_stim.mean(axis=0)*np.eye(64))\n",
    "fr_demean = np.matmul(fr, avg_prestim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "\n",
    "line1 = ax.plot(fr_demean[:,51])\n",
    "line2 = ax.plot(fr[:,51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip(np.arange(fr.shape[0]),fr[:,51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line1[0].get_color()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fr.shape\n",
    "[np.arange(start=int(row[0]/bin_samp), stop=int((row[0]+resp_length)/bin_samp)) for row in events]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_width = 30000 * .01\n",
    "bins = np.arange(start = 0, step = bin_width, stop = sig.shape[0] + 150)\n",
    "FR = np.histogram(spike_dict[51]['sample_no'], bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_dict[51]['sample_no'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "fr,fr_ts = openephys_utils.calc_FR(spike_dict, max_samp = sig.shape[0], min_samp=0, bin_ms = 0.001)\n",
    "\n",
    "# ax.plot(FR[1][:-1],FR[0])\n",
    "ax.plot(fr_ts,fr[:,51]*50)\n",
    "ax.scatter(spike_dict[51]['sample_no'], np.ones((spike_dict[51]['sample_no'].shape[0], 1)), color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff(events, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openephys_utils\n",
    "spike_dict = openephys_utils.threshold_crossings(sig_eraasr, multi_rejection=None)\n",
    "fr2,fr2_ts = openephys_utils.calc_FR(spike_dict, max_samp = sig.shape[0], min_samp=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spike_binary(spike_dict:dict, ax = None, stims:np.array = None, fs = 30000):\n",
    "    '''\n",
    "    Plot an on/off of channels over time. show the stimulations if given\n",
    "    '''\n",
    "\n",
    "    # create an axis if not given\n",
    "    if ax is None:\n",
    "        fig,ax = plt.subplots()\n",
    "\n",
    "    # for each channel, plot the spike times\n",
    "    for channel, data in spike_dict.items():\n",
    "        ax.vlines(data['sample_no']/fs, channel, channel+1)\n",
    "    \n",
    "    # plot the stimulation times if given\n",
    "    if stims is not None:\n",
    "        for i_stim in range(stims.shape[0]):\n",
    "            patch_array = np.array([[stims[i_stim,0]/fs,-1],\n",
    "                                        [stims[i_stim,1]/fs,-1],\n",
    "                                        [stims[i_stim,1]/fs,len(spike_dict.keys())],\n",
    "                                        [stims[i_stim,0]/fs,len(spike_dict.keys())]])\n",
    "            stim_patch = Polygon(patch_array, alpha=0.2, color='k')\n",
    "            ax.add_patch(stim_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PSTH(spike_dict:dict, stims:np.array, channel:int = 0, ax=None, fs=30000):\n",
    "    '''\n",
    "    Plot the PSTH for a single channel\n",
    "    \n",
    "    inputs:\n",
    "        spike_dict:dict     - firing rates\n",
    "        events:np.array     - event times\n",
    "        channel:int         - which channel are we working with?\n",
    "    '''\n",
    "\n",
    "    # create an axis if not given\n",
    "    if ax == None:\n",
    "        fig,ax = plt.subplots()\n",
    "\n",
    "    # split the spikes for the channel into a series of new channels\n",
    "    spikes = spike_dict[channel]['sample_no']\n",
    "    for i_stim in range(stims.shape[0]-1):\n",
    "        spike_subset = spikes[np.logical_and(spikes>=stims[i_stim,0], spikes<stims[i_stim+1,0])] - stims[i_stim,0]\n",
    "        ax.vlines(spike_subset/fs,i_stim,i_stim+1)\n",
    "        # create a patch at the stimulus point\n",
    "        patch_array = np.array([[0, i_stim], [stims[i_stim,1]/fs-stims[i_stim,0]/fs,i_stim],\n",
    "                                [stims[i_stim,1]/fs-stims[i_stim,0]/fs,i_stim+1], [0, i_stim+1]])\n",
    "        stim_patch = Polygon(patch_array, alpha=0.4, color='k')\n",
    "        ax.add_patch(stim_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spike_subset = spikes[51]['sample_no']\n",
    "for i_stim in range(events.shape[0]-1):\n",
    "        resh = spike_subset[np.logical_and(spike_subset>=events[i_stim,0], spike_subset<events[i_stim+1,0])] - events[i_stim,0]\n",
    "        ax.vlines(spike_subset,i_stim,i_stim+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_waveforms(spike_dict:dict, channel:int=0, fs:int=30000, ax=None):\n",
    "    '''\n",
    "    plot the mean threshold crossing for a channel, and a patch around the standard deviation.\n",
    "\n",
    "    could theoretically look at splitting into different units\n",
    "\n",
    "    inputs:\n",
    "        spike_dict\n",
    "        channels\n",
    "        std_flag\n",
    "        map\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    # create an axis if it doesn't exist\n",
    "    if ax is None:\n",
    "        fig,ax = plt.subplots()\n",
    "\n",
    "    # go into the waveforms\n",
    "    mean_wf = spike_dict[channel]['waveform'].mean(axis=0)\n",
    "    std_= spike_dict[channel]['waveform'].std(axis=0)\n",
    "\n",
    "    # elapsed ts\n",
    "    ts = [t/(fs/1000) for t in range(mean_wf.shape[0])]\n",
    "\n",
    "    # create std patch\n",
    "    std_array = np.ndarray((2*mean_wf.shape[0],2))\n",
    "    std_array[:mean_wf.shape[0],:] = np.column_stack((ts, mean_wf+std_))\n",
    "    std_array[mean_wf.shape[0]:,:] = np.column_stack((ts, mean_wf-std_))[::-1,:]\n",
    "    std_patch = Polygon(std_array, alpha=0.2, color = 'orange')\n",
    "\n",
    "    # plot em\n",
    "    ax.plot(ts, mean_wf, color='orange') \n",
    "    ax.add_patch(std_patch)\n",
    "    ax.set_xlabel('time (ms)')\n",
    "    ax.set_ylabel('magnitude (uV)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spike_binary(spikes, stims = events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multisave_PDF(fig, pdf):\n",
    "    pdf.savefig(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(nrows=2, sharex=True)\n",
    "\n",
    "openephys_utils.plot_PSTH(spike_dict=spike_dict, stims=events, ax=ax[0], channel=51)\n",
    "\n",
    "stim_reps_T = stim_reps.reshape((121,450,64)).transpose([1,0,2])\n",
    "for i_stim in range(121):\n",
    "    ax[1].plot(stim_reps_T[:,i_stim,51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(os.path.join(directory, 'channel_plots_minimum_nomultichannel.pdf')) as pdf:\n",
    "    fig, ax = plt.subplots(nrows = 2)\n",
    "    for channel in range(64):\n",
    "        # plot_PSTH(spikes, events, ax=ax[0], channel=channel)\n",
    "        # plot_mean_waveforms(spikes, ax=ax[1], channel=channel)\n",
    "        pdf.attach_note(f'Channel {channel}')\n",
    "        plot_PSTH(spike_dict, events, ax=ax[0], channel=channel)\n",
    "        plot_mean_waveforms(spike_dict, ax=ax[1], channel=channel)\n",
    "        pdf.savefig(fig)\n",
    "        for sub_ax in ax:\n",
    "            sub_ax.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_pass, low_pass = 300, 6000\n",
    "fs = 30000\n",
    "thresh_mult = -3.5\n",
    "\n",
    "sos_bpf = signal.butter(N = 8, Wn = [high_pass, low_pass], btype='bandpass', fs = fs, output='sos')\n",
    "sig_filt = signal.sosfiltfilt(sos=sos_bpf, x = sig_eraasr, axis=0)\n",
    "\n",
    "# find the threshold values for each channel\n",
    "thresholds = np.std(sig_filt, axis=0) * thresh_mult\n",
    "xings = np.nonzero(np.diff(np.where(sig_filt < thresholds, 1, 0), axis=0) == 1)\n",
    "\n",
    "# fig,ax = plt.subplots(nrows = len(channels))\n",
    "\n",
    "# for i_channel,channel in enumerate(channels):\n",
    "#     xings_channel = xings[0][xings[1] == channel]\n",
    "#     ax[i_channel].plot(timestamps, sig_filt[:,channel])\n",
    "#     ax[i_channel].plot(timestamps, sig_eraasr[:,channel])\n",
    "#     ax[i_channel].hlines(thresholds[channel], timestamps[0], timestamps[-1])\n",
    "\n",
    "#     ax[i_channel].vlines(timestamps[xings_channel], 1.2*np.min(sig_filt[:,channel]), 1.2*np.max(sig_filt[:,channel]))\n",
    "    \n",
    "\n",
    "# need to introduce some basic cross-channel artifact rejection\n",
    "\n",
    "# split into per-channel dictionary\n",
    "# bt = int(.0003*fs)\n",
    "# at = int(.0012 * fs)\n",
    "# spike_dict = {}\n",
    "# for i_channel in np.arange(sig.shape[1]):\n",
    "#     spike_ts = xings[0][xings[1] == i_channel] # sample #\n",
    "#     spike_wf = [sig_filt[ts-bt:ts+at,i_channel] for ts in spike_ts] # waveform\n",
    "\n",
    "#     spike_dict[i_channel] = {'sample_no':spike_ts, 'waveform':spike_wf}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [32, 36, 39, 48, 51] # the mapping from Sara just seems to be 1:1, but I'm not sure that's right...\n",
    "fig_filt, ax_filt = plt.subplots(nrows = len(channels), sharex=True, sharey=True)\n",
    "\n",
    "for i_channel, channel in enumerate(channels):\n",
    "    ax_filt[i_channel].plot(timestamps,sig_clean[:,channel])\n",
    "    ax_filt[i_channel].plot(timestamps,sig_filt[:,channel])\n",
    "    ax_filt[i_channel].hlines(np.std(sig_filt[:,channel])*-3.5, timestamps[0], timestamps[-1])\n",
    "    ax_filt[i_channel].set_title(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'Z:\\\\BrainPatch\\\\20240821\\\\Crimson__2024-08-21_13-29-59__20mA_MinOil_2ms'\n",
    "# directory = 'Z:\\\\BrainPatch\\\\20240821\\\\Crimson__2024-08-21_13-46-01__20mA_MinOil_2ms'\n",
    "# directory = 'Z:\\\\BrainPatch\\\\20240821\\\\Crimson__2024-08-21_15-10-03__20mA_MinOil_2ms'\n",
    "\n",
    "\n",
    "# directory = 'Z:\\\\BrainPatch\\\\20241002\\\\lateral\\\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um'\n",
    "directory = 'Z:\\\\BrainPatch\\\\20241002\\\\Crimson__2024-10-02_12-00-49__spontaneous_waking'\n",
    "\n",
    "# # load signals if we haven't already loaded it\n",
    "# if 'sig' not in locals():\n",
    "#     sig, timestamps, events, event_ts = open_sig_events(directory)\n",
    "session = Session(directory)\n",
    "print(session)\n",
    "\n",
    "\n",
    "for i_rec in range(len(session.recordnodes)):\n",
    "    print(f'{len(session.recordnodes[i_rec].recordings)} recording(s) in session \"{session.recordnodes[i_rec].directory}\"\\n')\n",
    "    recordings = session.recordnodes[i_rec].recordings\n",
    "    \n",
    "    for i_rec,recording in enumerate(recordings):\n",
    "        recording.load_continuous()\n",
    "        recording.load_spikes()\n",
    "        recording.load_events()\n",
    "        recording.load_messages()\n",
    "\n",
    "        print(f'Recording {i_rec} has:')\n",
    "        print(f'\\t{len(recording.continuous)} continuous streams')\n",
    "        print(f'\\t{len(recording.spikes)} spike streams')\n",
    "        print(f'\\t{len(recording.events)} event streams')\n",
    "    \n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the offline filtering to the online filtering, and take a look at the specific channels that I think might have some good stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel list -- \n",
    "channels = [32, 36, 39, 48, 51] # the mapping from Sara just seems to be 1:1, but I'm not sure that's right...\n",
    "\n",
    "# put together some filters\n",
    "# sos_h = signal.butter(N = 8, Wn = [150], btype = 'high', output = 'sos', fs=30000)\n",
    "# sos_l = signal.butter(N = 8, Wn = [6000], btype = 'low', output = 'sos', fs=30000)\n",
    "sos_bp = signal.butter(N=4, Wn = [150, 8000], btype='bandpass', output='sos', fs=30000)\n",
    "\n",
    "# timestamps -- raw\n",
    "# ts_raw = np.arange(len(session.recordnodes[0].recordings[0].continuous[0].sample_numbers))/session.recordnodes[0].recordings[0].continuous[0].metadata['sample_rate']\n",
    "ts_raw = session.recordnodes[0].recordings[0].continuous[0].sample_numbers/session.recordnodes[0].recordings[0].continuous[0].metadata['sample_rate']\n",
    "# ts_filt = np.arange(len(session.recordnodes[0].recordings[1].continuous[0].sample_numbers))/session.recordnodes[0].recordings[1].continuous[0].metadata['sample_rate']\n",
    "# ts_filt = session.recordnodes[0].recordings[1].continuous[0].sample_numbers/session.recordnodes[0].recordings[1].continuous[0].metadata['sample_rate']\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(nrows=len(channels), sharex=True)\n",
    "# raw recording -- filter it and plot it\n",
    "for i_channel, channel in enumerate(channels):\n",
    "    # sig_temp = signal.sosfilt(sos_l, signal.sosfilt(sos_h, session.recordnodes[0].recordings[0].continuous[0].samples[:,channel])/4)\n",
    "    sig_temp = signal.sosfilt(sos_bp, session.recordnodes[0].recordings[0].continuous[0].samples[:,channel])\n",
    "    ax[i_channel].plot(ts_raw, sig_temp, label='filtered offline')\n",
    "    ax[i_channel].plot(ts_raw, session.recordnodes[0].recordings[0].continuous[0].samples[:,channel], label='raw')\n",
    "    # ax[i_channel].plot(ts_filt, session.recordnodes[0].recordings[1].continuous[0].samples[:,channel], label='filtered online')\n",
    "\n",
    "    ax[i_channel].set_ylabel('uV')\n",
    "    ax[i_channel].legend()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_freq, ax_freq = plt.subplots(nrows=2)\n",
    "\n",
    "w, h = signal.sosfreqz(sos=sos_bp, fs = 30000)\n",
    "\n",
    "ax_freq[0].semilogx(w, 20*np.log10(np.abs(h)))\n",
    "ax_freq[1].semilogx(w, np.angle(h))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_map = loadmat(\"Z:\\\\BrainPatch\\\\20241002\\\\64-4shank-poly-brainpatch-chanMap.mat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab 50 ms after each stimulation. Set the mean of the stimulation period to 0.\n",
    "\n",
    "Find the minimum, maximum, depth of modulation, and time of each after the stimulation starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chans = 64 # 64 recording channels\n",
    "len_ms = 150\n",
    "t_len = len_ms*30 # 52 ms * 30 khz\n",
    "n_events = events.shape[0] # number of stimulation events\n",
    "\n",
    "# set up the events to plot patches\n",
    "events = np.argwhere(np.diff(recording.continuous[0].samples[:,64]>5000) == 1)\n",
    "events = events.reshape([int(events.shape[0]/2),2])\n",
    "event_ts = events/recording.continuous[0].metadata['sample_rate']\n",
    "\n",
    "responses = np.zeros((n_events, t_len, n_chans))\n",
    "maxs = np.zeros((n_events, n_chans))\n",
    "rel_maxs = np.zeros((n_events, n_chans))\n",
    "abs_maxs = np.zeros((n_events, n_chans))\n",
    "mins = np.zeros((n_events, n_chans))\n",
    "rel_mins = np.zeros((n_events, n_chans))\n",
    "abs_mins = np.zeros((n_events, n_chans))\n",
    "\n",
    "for i_event, event in enumerate(events):\n",
    "    response = sig[event[0]:event[0]+len_ms*30,:]\n",
    "    means = np.mean(sig[event[0]+4:event[1]-4,:], axis = 0)\n",
    "    responses[i_event,:,:] = response - means # response for each channel\n",
    "    \n",
    "    mins[i_event,:] = np.min(response - means, axis=0)\n",
    "    rel_mins[i_event,:] = np.argmin(response - means, axis=0)/30000\n",
    "    abs_mins[i_event,:] = rel_mins[i_event,:] + event_ts[i_event,0]\n",
    "\n",
    "    # maxs[i_event,:] = np.max(response[int(rel_mins*30000),:] - means, axis=0) # only interested in stuff after the negative deviation\n",
    "    # rel_maxs[i_event,:] = np.argmax(response[int(rel_mins*30000),:] - means, axis=0)/30000\n",
    "    # abs_maxs[i_event,:] = rel_maxs[i_event,:] + event_ts[i_event,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same thing, but look at the same channel for a couple of different stimulation amplitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average stimulation responses\n",
    "\n",
    "let's take a look at the average stimulation response for a couple different electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'Z:\\\\BrainPatch\\\\20240821\\\\Crimson__2024-08-21_13-46-01__20mA_MinOil_2ms'\n",
    "directory = 'Z:\\\\BrainPatch\\\\20240821\\\\Crimson__2024-08-21_13-29-59__20mA_MinOil_2ms'\n",
    "\n",
    "# get the signal etc\n",
    "signal, timestamps, events, event_ts = open_sig_events(directory)\n",
    "\n",
    "fig_avg, ax_avg = plt.subplots()\n",
    "\n",
    "for channel in [0,5,10,15,20]:\n",
    "    plot_avg_response(signal, events, len_ms= 40, channel=channel, ax=ax_avg)\n",
    "\n",
    "\n",
    "ax_avg.axvspan(0, 2, color='k', alpha=.1, label='Stimulation Period')\n",
    "\n",
    "# clean up the plot, add a legend etc\n",
    "ax_avg.legend()\n",
    "for spine in ['top','bottom','right','left']:\n",
    "    ax_avg.spines[spine].set_visible(False)\n",
    "\n",
    "ax_avg.set_xlabel('Time after stimulation onset (ms)')\n",
    "ax_avg.set_ylabel('Magnitude (uV)')\n",
    "ax_avg.set_title('Mean stimulation responses with standard deviations\\n20 mA, 400 um')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-file analysis\n",
    "\n",
    "Looking at the responses over different distances and currents\n",
    "\n",
    "First we need to put together a list of the different recordings and the parameters\n",
    "\n",
    "### August 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## August 21 data\n",
    "# lets go through recordings in groups of locations\n",
    "base_dir = 'Z:\\\\BrainPatch\\\\20240821'\n",
    "\n",
    "dir_400 = ['Crimson__2024-08-21_13-44-07__10mA_MinOil_2ms','Crimson__2024-08-21_13-46-01__20mA_MinOil_2ms','Crimson__2024-08-21_13-47-40__15mA_MinOil_2ms','Crimson__2024-08-21_13-49-43__10mA_MinOil_2ms','Crimson__2024-08-21_13-51-50__5mA_MinOil_2ms']\n",
    "dir_700 = ['Crimson__2024-08-21_13-56-49__5mA_MinOil_2ms','Crimson__2024-08-21_13-58-50__10mA_MinOil_2ms','Crimson__2024-08-21_14-00-53__15mA_MinOil_2ms','Crimson__2024-08-21_14-02-54__20mA_MinOil_2ms']\n",
    "dir_1000 = ['Crimson__2024-08-21_14-05-52__5mA_MinOil_2ms','Crimson__2024-08-21_14-07-41__10mA_MinOil_2ms','Crimson__2024-08-21_14-09-46__15mA_MinOil_2ms','Crimson__2024-08-21_14-11-45__20mA_MinOil_2ms']\n",
    "dir_1300 = ['Crimson__2024-08-21_14-14-26__5mA_MinOil_2ms','Crimson__2024-08-21_14-16-02__10mA_MinOil_2ms','Crimson__2024-08-21_14-17-58__15mA_MinOil_2ms','Crimson__2024-08-21_14-20-21__20mA_MinOil_2ms']\n",
    "dir_1600 = ['Crimson__2024-08-21_14-23-13__5mA_MinOil_2ms','Crimson__2024-08-21_14-25-16__10mA_MinOil_2ms','Crimson__2024-08-21_14-27-12__15mA_MinOil_2ms','Crimson__2024-08-21_14-29-03__20mA_MinOil_2ms']\n",
    "\n",
    "# dictionary of direct groups\n",
    "dir_dict = {400: dir_400, 700:dir_700, 1000:dir_1000, 1300:dir_1300, 1600:dir_1600}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### September 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = 'Z:\\\\BrainPatch\\\\20240925\\\\No_Mineral_Oil'\n",
    "base_dir = 'Z:\\\\BrainPatch\\\\20240925'\n",
    "\n",
    "dir_400 = glob.glob('*0mm_2ms*', root_dir=base_dir) + glob.glob('*2ms_0mm*', root_dir=base_dir)\n",
    "dir_600 = glob.glob('*2ms_.6mm', root_dir=base_dir) \n",
    "dir_1200 = glob.glob('*2ms_1.2mm', root_dir=base_dir) \n",
    "dir_1500 = glob.glob('*2ms_1.5mm', root_dir=base_dir) \n",
    "\n",
    "dir_dict = {400:dir_400, 600:dir_600, 1200:dir_1200, 1500:dir_1500}\n",
    "\n",
    "channel = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### October 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'Z:\\\\BrainPatch\\\\20241002\\\\lateral'\n",
    "\n",
    "dir_300 = glob.glob('*2ms_400um', root_dir=base_dir)\n",
    "dir_600 = glob.glob('*2ms_600um', root_dir=base_dir)\n",
    "dir_900 = glob.glob('*2ms_900um', root_dir=base_dir)\n",
    "dir_1200 = glob.glob('*2ms_1200us', root_dir=base_dir)\n",
    "dir_1500 = glob.glob('*2ms_1500um', root_dir=base_dir)\n",
    "\n",
    "dir_dict = {300:dir_300, 600:dir_600, 900:dir_900, 1200:dir_1200, 1500:dir_1500}\n",
    "\n",
    "channel = 36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's take a look at a single channel for a few different current levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_avg_dist, ax_avg_dist = plt.subplots()\n",
    "\n",
    "channel = 48\n",
    "distance = 1500\n",
    "\n",
    "for sub_dir in dir_1500:\n",
    "    directory = os.path.join(base_dir,sub_dir)\n",
    "\n",
    "    # get the signal etc\n",
    "    sig, timestamps, events, event_ts = open_sig_events(directory)\n",
    "\n",
    "    amp = re.search('(\\d)+mA',sub_dir)[0]\n",
    "    plot_avg_response(sig, events, len_ms= 40, channel=channel, ax=ax_avg_dist, label=amp)\n",
    "\n",
    "ax_avg_dist.axvspan(0, 2, color='k', alpha=.1, label='Stimulation Period')\n",
    "    \n",
    "# clean up the plot, add a legend etc\n",
    "ax_avg_dist.legend()\n",
    "for spine in ['top','bottom','right','left']:\n",
    "    ax_avg_dist.spines[spine].set_visible(False)\n",
    "\n",
    "ax_avg_dist.set_xlabel('Time after stimulation onset (ms)')\n",
    "ax_avg_dist.set_ylabel('Magnitude (uV)')\n",
    "ax_avg_dist.set_title(f'Mean stimulation at different stimulation amplitudes\\nChannel {channel}, {distance} um')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all of the different directories, then put the mean and median negative deviation for each channel into a dataframe for easy analysis and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_df = pd.DataFrame(columns=['Channel_no','Current','Distance','uMin','uMin_ts','medMin','medMin_ts'])\n",
    "\n",
    "for dist,dir_list in dir_dict.items():\n",
    "    for sub_dir in dir_list:\n",
    "        directory = os.path.join(base_dir, sub_dir) # go through the subdir, check to make sure it exists and that there's data inside\n",
    "        if not os.path.exists(directory):\n",
    "            continue\n",
    "        if not len([file for file in os.listdir(directory) if not file.startswith('.')]): # if the directory is empty, skip it\n",
    "            continue\n",
    "\n",
    "\n",
    "        # open the directory\n",
    "        sig, timestamps, events, event_ts = open_sig_events(directory)\n",
    "\n",
    "        # pull out the stim responses\n",
    "        mins, rel_mins, abs_mins = find_responses(sig, events)\n",
    "\n",
    "        # means and medians for each channel\n",
    "        uMins = np.mean(mins, axis=0)\n",
    "        uMins_ts = np.mean(rel_mins, axis=0)\n",
    "        medMins = np.median(mins, axis=0)\n",
    "        medMins_ts = np.median(rel_mins, axis=0)\n",
    "\n",
    "        # a nested dictionary of all of the channels responses\n",
    "        tdict = {ii:{'Channel_no':ii, \n",
    "                'Current':re.search('([0-9]+)mA', sub_dir)[1],\n",
    "                'Distance': dist,\n",
    "                'uMin':uMins[ii],\n",
    "                'uMin_ts':uMins_ts[ii],\n",
    "                'medMin':medMins[ii],\n",
    "                'medMin_ts':medMins_ts[ii],\n",
    "                } for ii in range(64)}\n",
    "\n",
    "        t_df = pd.DataFrame.from_dict(tdict, orient='index') # create a dataframe\n",
    "\n",
    "        resp_df = pd.concat([resp_df, t_df], ignore_index=True)\n",
    "\n",
    "resp_df.Current = resp_df.Current.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the effects of distance on the magnitude of the response for the different current levels. Different channels on different axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currents = resp_df.Current.unique()\n",
    "currents.sort()\n",
    "# channels = [10, 15, 20, 25, 30]\n",
    "channels = np.arange(64, step = 5)\n",
    "\n",
    "fig_dist,ax_dist = plt.subplots(nrows=len(channels), sharex=True, sharey=True)\n",
    "# fig_time, ax_time = plt.subplots(nrows=len(channels), sharex=True, sharey=True)\n",
    "for i_chan,chan in enumerate(channels):\n",
    "    for i_curr,curr in enumerate(currents):\n",
    "        dist_cmp = resp_df.loc[(resp_df.Current==curr) * (resp_df.Channel_no==chan)]\n",
    "        ax_dist[i_chan].plot(dist_cmp.Distance, dist_cmp.uMin)\n",
    "        # ax_time[i_chan].plot(dist_cmp.Distance, dist_cmp.uMin_ts)\n",
    "\n",
    "    ax_dist[i_chan].legend([f'{current} mA' for current in currents], loc=4)\n",
    "    ax_dist[i_chan].set_title(f'Channel {chan}')\n",
    "    ax_dist[i_chan].set_ylabel('Magnitude (uV)')\n",
    "\n",
    "\n",
    "    # ax_time[i_chan].legend([f'{current} mA' for current in currents], loc=4)\n",
    "    # ax_time[i_chan].set_title(f'Channel {chan}')\n",
    "    # ax_time[i_chan].set_ylabel('Time (ms)')\n",
    "\n",
    "    # remove the outer boxes\n",
    "    for spine in ['top','bottom','right','left']:\n",
    "        ax_dist[i_chan].spines[spine].set_visible(False)\n",
    "        # ax_time[i_chan].spines[spine].set_visible(False)\n",
    "    \n",
    "\n",
    "ax_dist[-1].set_xlabel('Distance (um)')\n",
    "fig_dist.suptitle('Mean response minimum as a function of distance (per current level)')\n",
    "\n",
    "\n",
    "# ax_time[-1].set_xlabel('Distance (um)')\n",
    "# fig_time.suptitle('Mean minimum time as a function of distance (per current level)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean negative deviation for all channels as a function of distance. Different axis per current level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currents = resp_df.Current.unique()\n",
    "distances = resp_df.Distance.unique()\n",
    "currents.sort()\n",
    "distances.sort()\n",
    "\n",
    "fig_min_scatter,ax_min_scatter = plt.subplots(ncols=len(currents), sharex=True, sharey=True)\n",
    "for i_curr,curr in enumerate(currents):\n",
    "    dist_cmp = resp_df.loc[resp_df.Current==curr ]\n",
    "    ax_min_scatter[i_curr].scatter(dist_cmp.Distance, dist_cmp.uMin, s = 2, color='grey')\n",
    "    current_means = dist_cmp.groupby('Distance').mean('uMin')\n",
    "    ax_min_scatter[i_curr].plot(current_means.index, current_means.uMin, color='k')\n",
    "\n",
    "    # ax_min_scatter[i_curr].legend([f'{current} mA' for current in currents], loc=4)\n",
    "    ax_min_scatter[i_curr].set_title(f'LED current: {curr} mA')\n",
    "    ax_min_scatter[i_curr].set_xlabel('Distance (um)')\n",
    "\n",
    "\n",
    "    # remove the outer boxes\n",
    "    for spine in ['top','bottom','right','left']:\n",
    "        ax_min_scatter[i_curr].spines[spine].set_visible(False)\n",
    "        # ax_time[i_chan].spines[spine].set_visible(False)\n",
    "    \n",
    "\n",
    "ax_min_scatter[0].set_ylabel('Magnitude (uV)')\n",
    "fig_dist.suptitle('Mean response minimum as a function of distance (per current level)')\n",
    "\n",
    "\n",
    "# ax_time[-1].set_xlabel('Distance (um)')\n",
    "# fig_time.suptitle('Mean minimum time as a function of distance (per current level)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time of the minimum value as a function of current. Each distance on a different plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currents = resp_df.Current.unique()\n",
    "distances = resp_df.Distance.unique()\n",
    "currents.sort()\n",
    "distances.sort()\n",
    "\n",
    "fig_time_scatter,ax_time_scatter = plt.subplots(ncols=len(distances), sharex=True, sharey=True)\n",
    "for i_dist,dist in enumerate(distances):\n",
    "    curr_cmp = resp_df.loc[resp_df.Distance == dist]\n",
    "    ax_time_scatter[i_dist].scatter(curr_cmp.Current, curr_cmp.uMin_ts, s = 2, color='blue')\n",
    "    curr_means = curr_cmp.groupby('Current').mean('uMin_ts')\n",
    "    ax_time_scatter[i_dist].plot(curr_means.index, curr_means.uMin_ts, color='k')\n",
    "\n",
    "    # ax_time_scatter[i_dist].legend([f'{distent} mA' for distent in distents], loc=4)\n",
    "    ax_time_scatter[i_dist].set_title(f'Distance: {dist}um')\n",
    "    ax_time_scatter[i_dist].set_xlabel('Current (mA)')\n",
    "\n",
    "\n",
    "    # remove the outer boxes\n",
    "    for spine in ['top','bottom','right','left']:\n",
    "        ax_time_scatter[i_dist].spines[spine].set_visible(False)\n",
    "        # ax_time[i_chan].spines[spine].set_visible(False)\n",
    "    \n",
    "\n",
    "ax_time_scatter[0].set_ylabel('Time (ms)')\n",
    "fig_dist.suptitle('Mean response minimum as a function of current (per distance)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Channel spike processing\n",
    "\n",
    "\n",
    "October 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'Z:\\\\BrainPatch\\\\20241002\\\\lateral'\n",
    "\n",
    "dir_300 = glob.glob(os.path.join(base_dir,'*2ms_400um'))\n",
    "dir_600 = glob.glob(os.path.join(base_dir,'*2ms_600um'))\n",
    "dir_900 = glob.glob(os.path.join(base_dir,'*2ms_900um'))\n",
    "dir_1200 = glob.glob(os.path.join(base_dir,'*2ms_1200us'))\n",
    "dir_1500 = glob.glob(os.path.join(base_dir,'*2ms_1500um'))\n",
    "\n",
    "dir_dict = {300:dir_300, 600:dir_600, 900:dir_900, 1200:dir_1200, 1500:dir_1500}\n",
    "\n",
    "channel = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [51]\n",
    "with PdfPages(os.path.join(base_dir, f'channel_{channel}.pdf')) as pdf:\n",
    "    fig, ax = plt.subplots(nrows = 2)\n",
    "\n",
    "    for directory in dir_300:\n",
    "        amplitude = re.search('\\d{1,2}mA', directory)[0]\n",
    "        if not all([var in locals() for var in ['sig', 'timestamps', 'events', 'events_ts']]):\n",
    "            sig, timestamps, stims, stim_ts = openephys_utils.open_sig_stims(directory)\n",
    "\n",
    "        sig_eraasr = openephys_utils.ERAASR(sig)\n",
    "        sig_mine = openephys_utils.ERAASR(sig, mode='mine')\n",
    "\n",
    "        spike_dict = openephys_utils.threshold_crossings(sig_eraasr, multi_rejection=None, low_cutoff=-20)\n",
    "\n",
    "        for channel in channels:\n",
    "            openephys_utils.plot_mean_waveforms(spike_dict, ax=ax[0], channel=channel)\n",
    "            ax[0].set_title('Threshold Crossing Waveform')\n",
    "            openephys_utils.plot_PSTH(spike_dict, stims, ax=ax[1], channel=channel)\n",
    "            ax[1].set_title('')\n",
    "            ax[1].set_xlabel('Time (s)')\n",
    "            ax[1].set_ylabel('Stimulation Number')\n",
    "            # plt.title(f'Channel {channel}, {directory}')\n",
    "            fig.text(0.05, 0.95, f'Channel {channel}, {amplitude}', transform=fig.transFigure, size=24)\n",
    "            pdf.savefig(fig)\n",
    "            for sub_ax in ax:\n",
    "                sub_ax.cla()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put together mean firing rates, PSTHs, and units for highest firing channels that seem like reasonable waveforms. Iterate through all conditions for a particular unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from open_ephys.analysis import Session\n",
    "from scipy import signal\n",
    "from scipy.io import loadmat\n",
    "# from scipy.fft import fft, fftfreq\n",
    "# from scipy.signal.windows import gaussian\n",
    "from sklearn.decomposition import PCA\n",
    "import os, glob, re\n",
    "import openephys_utils \n",
    "\n",
    "\n",
    "# %matplotlib ipympl\n",
    "%matplotlib qt\n",
    "\n",
    "# pdfPages for saving images to a multi-page PDF\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# status bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# kilosort\n",
    "import kilosort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the mean post-stim firing rates and waveform for all conditions for a couple of channels.\n",
    "\n",
    "This turned out pretty messy, so the next cell down is the same thing for just a few current/distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [36, 40, 42, 46, 51]\n",
    "bin_sec = .001\n",
    "base_dir = 'Z:\\\\BrainPatch\\\\20241002\\\\lateral'\n",
    "\n",
    "figs = {}\n",
    "for channel in channels:\n",
    "    fig = plt.figure()\n",
    "    gs = GridSpec(3,2, fig)\n",
    "    ax_wf = fig.add_subplot(gs[0,0])\n",
    "    ax_means = fig.add_subplot(gs[1,:])\n",
    "    # ax_meanmax = fig.add_subplot(gs[2,:])\n",
    "    figs[channel] = {'figure':fig, 'thresh':ax_wf, 'fr_means':ax_means}\n",
    "\n",
    "# fig_max,ax_max = plt.subplots()\n",
    "\n",
    "directories = [directory for directory in os.listdir(base_dir) if '2ms' in directory]\n",
    "for directory in tqdm(directories):\n",
    "    current = int(re.search('(\\d{1,2})mA', directory)[1])\n",
    "    distance = int(re.search('(\\d{3,4})um', directory)[1])\n",
    "\n",
    "    print(f'{current}mA {distance}mm')\n",
    "\n",
    "    # read everything\n",
    "    sig, timestamps, stims, stim_ts = openephys_utils.open_sig_stims(os.path.join(base_dir,directory))\n",
    "\n",
    "    # clean, pull out threshold crossings, get firing rates\n",
    "    sig_eraasr = openephys_utils.ERAASR(sig)\n",
    "    spike_dict = openephys_utils.threshold_crossings(sig_eraasr, multi_rejection=None, low_cutoff=-20)\n",
    "    fr, bins = openephys_utils.calc_FR(spike_dict, max_samp = sig_eraasr.shape[0], min_samp = 0, bin_sec = bin_sec)\n",
    "\n",
    "    mean_fr,std_fr = openephys_utils.mean_stim_FR(fr, stims, bin_sec = bin_sec, normalize=False, resp_length_samp = 4000)\n",
    "\n",
    "    for channel in channels: # for each of the channels we want\n",
    "        # make the plots and label them, etc\n",
    "        openephys_utils.plot_mean_waveforms(spike_dict = spike_dict, channel=channel, ax=figs[channel]['thresh'], label=f'{current}mA, {distance/1000}mm')\n",
    "        openephys_utils.plot_mean_FR(mean_FR=mean_fr, channel = channel, ax = figs[channel]['fr_means'], label=f'{current}mA, {distance/1000}mm')\n",
    "\n",
    "\n",
    "\n",
    "# add a legend to everything\n",
    "for fig in figs:\n",
    "    fig['thresh'].legend()\n",
    "    fig['fr_means'].legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean post-stim firing rates and waveforms for just a couple recordings at 400 um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77529be87734efebbab5f161739a1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20mA 400mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_12-26-46__20mA_2ms_400um\\raw_signal.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "channels = [36, 40, 42, 46, 51]\n",
    "bin_sec = .001\n",
    "base_dir = 'Z:\\\\BrainPatch\\\\20241002\\\\lateral'\n",
    "\n",
    "\n",
    "figs = {}\n",
    "for channel in channels:\n",
    "    fig = plt.figure()\n",
    "    gs = GridSpec(3,2, fig)\n",
    "    ax_wf = fig.add_subplot(gs[0,0])\n",
    "    ax_means = fig.add_subplot(gs[1,:])\n",
    "    # ax_meanmax = fig.add_subplot(gs[2,:])\n",
    "    figs[channel] = {'figure':fig, 'thresh':ax_wf, 'fr_means':ax_means}\n",
    "\n",
    "# directories = [directory for directory in os.listdir(base_dir) if '2ms' in directory]\n",
    "# directories = ['Crimson__2024-10-02_12-26-46__20mA_2ms_400um',\n",
    "            #    'Crimson__2024-10-02_12-35-37__15mA_2ms_400um',\n",
    "            #    'Crimson__2024-10-02_12-39-41__10mA_2ms_400um',\n",
    "            #    'Crimson__2024-10-02_12-49-56__5mA_2ms_400um']\n",
    "directories = ['Crimson__2024-10-02_12-26-46__20mA_2ms_400um']\n",
    "for directory in tqdm(directories):\n",
    "    current = int(re.search('(\\d{1,2})mA', directory)[1])\n",
    "    distance = int(re.search('(\\d{3,4})um', directory)[1])\n",
    "\n",
    "    print(f'{current}mA {distance}mm')\n",
    "\n",
    "    # read everything\n",
    "    sig, timestamps, stims, stim_ts = openephys_utils.open_sig_stims(os.path.join(base_dir,directory))\n",
    "\n",
    "    # clean, pull out threshold crossings, get firing rates\n",
    "    sig_eraasr = openephys_utils.ERAASR(sig)\n",
    "    spike_dict = openephys_utils.threshold_crossings(sig_eraasr, multi_rejection=None, low_cutoff=-20, thresh_mult=-4.5)\n",
    "    fr, bins = openephys_utils.calc_FR(spike_dict, max_samp = sig_eraasr.shape[0], min_samp = 0, bin_sec = bin_sec)\n",
    "\n",
    "    mean_fr,std_fr = openephys_utils.mean_stim_FR(fr, stims, bin_sec = bin_sec, normalize=False, resp_length_samp = 4000)\n",
    "\n",
    "    for i_channel, channel in enumerate(channels): # for each of the channels we want\n",
    "        # make the plots and label them, etc\n",
    "        openephys_utils.plot_mean_waveforms(spike_dict = spike_dict, channel=channel, ax=figs[channel]['thresh'], label=f'{current}mA, {distance/1000}mm')\n",
    "        openephys_utils.plot_mean_FR(mean_FR=mean_fr/10, std_FR=std_fr/10, channel = channel, ax = figs[channel]['fr_means'], label=f'{current}mA, {distance/1000}mm', bin_ms = bin_sec * 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same process as above, but storing a \"max firing rate\" dictionary similar to the one for the LFPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb03e86c15754d38a034cad793675f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20mA 400mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um\\raw_signal.pkl\n",
      "20mA 400mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_12-24-31__20mA_2ms_400um\\raw_signal.pkl\n",
      "20mA 400mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_12-26-46__20mA_2ms_400um\\raw_signal.pkl\n",
      "15mA 400mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_12-35-37__15mA_2ms_400um\\raw_signal.pkl\n",
      "15mA 400mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_12-37-44__15mA_2ms_400um\\raw_signal.pkl\n",
      "10mA 400mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_12-39-41__10mA_2ms_400um\\raw_signal.pkl\n",
      "10mA 400mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_12-41-41__10mA_2ms_400um\\raw_signal.pkl\n",
      "5mA 400mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_12-49-56__5mA_2ms_400um\\raw_signal.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin\\AppData\\Local\\Temp\\4\\ipykernel_109140\\674829182.py:27: RuntimeWarning: Mean of empty slice.\n",
      "  'spike':spike_dict[ii]['waveform'].mean(axis=0)} for ii in channels]\n",
      "e:\\Kevin\\Anaconda\\kilosort\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15mA 400mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_12-52-58__15mA_2ms_400um\\raw_signal.pkl\n",
      "5mA 600mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_13-10-56__5mA_2ms_600um\\raw_signal.pkl\n",
      "10mA 600mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_13-17-09__10mA_2ms_600um\\raw_signal.pkl\n",
      "15mA 600mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_13-20-08__15mA_2ms_600um\\raw_signal.pkl\n",
      "20mA 600mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_13-28-37__20mA_2ms_600um\\raw_signal.pkl\n",
      "20mA 900mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_13-31-23__20mA_2ms_900um\\raw_signal.pkl\n",
      "15mA 900mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_13-39-44__15mA_2ms_900um\\raw_signal.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin\\AppData\\Local\\Temp\\4\\ipykernel_109140\\674829182.py:27: RuntimeWarning: Mean of empty slice.\n",
      "  'spike':spike_dict[ii]['waveform'].mean(axis=0)} for ii in channels]\n",
      "e:\\Kevin\\Anaconda\\kilosort\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10mA 900mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_13-42-12__10mA_2ms_900um\\raw_signal.pkl\n",
      "5mA 900mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_13-51-03__5mA_2ms_900um\\raw_signal.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin\\AppData\\Local\\Temp\\4\\ipykernel_109140\\674829182.py:27: RuntimeWarning: Mean of empty slice.\n",
      "  'spike':spike_dict[ii]['waveform'].mean(axis=0)} for ii in channels]\n",
      "e:\\Kevin\\Anaconda\\kilosort\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5mA 1200mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_13-54-13__5mA_2ms_1200um\\raw_signal.pkl\n",
      "10mA 1200mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_14-02-07__10mA_2ms_1200um\\raw_signal.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin\\AppData\\Local\\Temp\\4\\ipykernel_109140\\674829182.py:27: RuntimeWarning: Mean of empty slice.\n",
      "  'spike':spike_dict[ii]['waveform'].mean(axis=0)} for ii in channels]\n",
      "e:\\Kevin\\Anaconda\\kilosort\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15mA 1200mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_14-05-20__15mA_2ms_1200um\\raw_signal.pkl\n",
      "20mA 1200mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_14-12-40__20mA_2ms_1200um\\raw_signal.pkl\n",
      "20mA 1500mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_14-15-26__20mA_2ms_1500um\\raw_signal.pkl\n",
      "15mA 1500mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_14-22-56__15mA_2ms_1500um\\raw_signal.pkl\n",
      "10mA 1500mm\n",
      "loading previously converted file Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_14-26-40__10mA_2ms_1500um\\raw_signal.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin\\AppData\\Local\\Temp\\4\\ipykernel_109140\\674829182.py:27: RuntimeWarning: Mean of empty slice.\n",
      "  'spike':spike_dict[ii]['waveform'].mean(axis=0)} for ii in channels]\n",
      "e:\\Kevin\\Anaconda\\kilosort\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "channels = np.arange(64)\n",
    "bin_sec = .005\n",
    "base_dir = 'Z:\\\\BrainPatch\\\\20241002\\\\lateral'\n",
    "\n",
    "fr_list = []\n",
    "directories = [directory for directory in os.listdir(base_dir) if '2ms' in directory]\n",
    "for directory in tqdm(directories):\n",
    "    current = int(re.search('(\\d{1,2})mA', directory)[1])\n",
    "    distance = int(re.search('(\\d{3,4})um', directory)[1])\n",
    "\n",
    "    print(f'{current}mA {distance}mm')\n",
    "\n",
    "    # read everything\n",
    "    sig, timestamps, stims, stim_ts = openephys_utils.open_sig_stims(os.path.join(base_dir,directory))\n",
    "\n",
    "    # clean, pull out threshold crossings, get firing rates\n",
    "    sig_eraasr = openephys_utils.ERAASR(sig, stims)\n",
    "    spike_dict = openephys_utils.threshold_crossings(sig_eraasr, multi_rejection=None, low_cutoff=-20, thresh_mult=-4.5)\n",
    "    fr, bins = openephys_utils.calc_FR(spike_dict, max_samp = sig_eraasr.shape[0], min_samp = 0, bin_sec = bin_sec)\n",
    "\n",
    "    mean_fr,std_fr = openephys_utils.mean_stim_FR(fr, stims, bin_sec = bin_sec, normalize=False, resp_length_samp = 4000)\n",
    "\n",
    "    temp_list = [{'Channel_no':ii,\n",
    "                  'current':current,\n",
    "                  'distance':distance,\n",
    "                  'max_fr':mean_fr[:,ii].max(),\n",
    "                  'spike':spike_dict[ii]['waveform'].mean(axis=0)} for ii in channels]\n",
    "    \n",
    "    fr_list.extend(temp_list)\n",
    "\n",
    "\n",
    "fr_df = pd.DataFrame(fr_list)\n",
    "\n",
    "with open(os.path.join(base_dir,'firing_rates.pkl'), 'wb') as fid:\n",
    "    pd.to_pickle(fr_df, fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots for the max firing rates as a function of distance or current. Also looking at the least squares fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'firing rate (Hz)')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig_fr, ax_fr = plt.subplots()\n",
    "\n",
    "electrode_map = loadmat('Z:\\\\BrainPatch\\\\20241002\\\\64-4shank-poly-brainpatch-chanMap.mat')\n",
    "cmap = np.array(plt.colormaps.get_cmap('tab10').colors)\n",
    "curr = 15\n",
    "\n",
    "intrinsic_dist = electrode_map['xcoords'][fr_df.Channel_no].astype(float) - 375\n",
    "fr_df['Chan_dist'] = np.sqrt(fr_df.distance.astype(float)**2 + intrinsic_dist.ravel()**2)\n",
    "fr_temp = fr_df.loc[fr_df.current.eq(curr)]\n",
    "\n",
    "ax_fr.scatter(fr_temp['Chan_dist'], fr_temp['max_fr'], c = cmap[electrode_map['kcoords'][fr_temp.Channel_no],:])\n",
    "# ax_fr.\n",
    "\n",
    "# # lstsq regression\n",
    "# B = np.linalg.lstsq(np.column_stack([fr_temp['Chan_dist'], np.ones_like(fr_temp['Chan_dist'])]), fr_temp['distance'])\n",
    "# Xi = np.array([[fr_temp['distance'].min(),1],[fr_temp['distance'].max(),1]])\n",
    "# ax_fr.plot(Xi[:,0], np.matmul(Xi,B[0]), color='black')\n",
    "\n",
    "ax_fr.set_xlabel('distance (um)')\n",
    "ax_fr.set_ylabel('firing rate (Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cleaned stuff, let's try running things through kilosort again to compare with the plain threshold crossings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xc': array([500., 500., 500., 500., 500., 500., 500., 500., 500., 500., 500.,\n",
       "        750., 500., 750., 500., 750., 500., 750., 500., 750., 750., 750.,\n",
       "        500., 750., 750., 750., 750., 750., 750., 750., 750., 750.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0., 250.,   0.,   0.,   0.,\n",
       "        250.,   0., 250.,   0., 250.,   0., 250.,   0., 250.,   0., 250.,\n",
       "        250., 250., 250., 250., 250., 250., 250., 250., 250.],\n",
       "       dtype=float32),\n",
       " 'yc': array([  0., 250., 200., 350., 150., 450.,  50., 400., 100., 600., 300.,\n",
       "        750., 500., 550., 700., 350., 650., 700., 550., 100., 500., 600.,\n",
       "        750.,  50., 300., 400., 250., 200.,   0., 450., 150., 650., 100.,\n",
       "        600.,  50., 400., 200., 250., 350., 450., 700.,   0., 550., 650.,\n",
       "        500., 150., 600., 750., 750., 300., 550., 500., 350., 700., 150.,\n",
       "        650.,   0., 450., 100., 400., 250., 300.,  50., 200.],\n",
       "       dtype=float32),\n",
       " 'kcoords': array([3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 4., 3., 4., 3., 4., 3.,\n",
       "        4., 3., 4., 4., 4., 3., 4., 4., 4., 4., 4., 4., 4., 4., 4., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 2., 1., 2., 1., 2., 1., 2.,\n",
       "        1., 2., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.], dtype=float32),\n",
       " 'chanMap': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "        51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]),\n",
       " 'n_chan': 64}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kilosort.io.load_probe('Z:\\\\BrainPatch\\\\20241002\\\\64-4shank-poly-brainpatch-chanMap.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kilosort.run_kilosort: Kilosort version 4.0.17\n",
      "kilosort.run_kilosort: Kilosort version 4.0.17\n",
      "kilosort.run_kilosort: Kilosort version 4.0.17\n",
      "kilosort.run_kilosort: Kilosort version 4.0.17\n",
      "kilosort.run_kilosort: Kilosort version 4.0.17\n",
      "kilosort.run_kilosort: Sorting Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um\\sig_eraasr.npy\n",
      "kilosort.run_kilosort: Sorting Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um\\sig_eraasr.npy\n",
      "kilosort.run_kilosort: Sorting Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um\\sig_eraasr.npy\n",
      "kilosort.run_kilosort: Sorting Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um\\sig_eraasr.npy\n",
      "kilosort.run_kilosort: Sorting Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um\\sig_eraasr.npy\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: Using GPU for PyTorch computations. Specify `device` to change this.\n",
      "kilosort.run_kilosort: Using GPU for PyTorch computations. Specify `device` to change this.\n",
      "kilosort.run_kilosort: Using GPU for PyTorch computations. Specify `device` to change this.\n",
      "kilosort.run_kilosort: Using GPU for PyTorch computations. Specify `device` to change this.\n",
      "kilosort.run_kilosort: Using GPU for PyTorch computations. Specify `device` to change this.\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Computing preprocessing variables.\n",
      "kilosort.run_kilosort: Computing preprocessing variables.\n",
      "kilosort.run_kilosort: Computing preprocessing variables.\n",
      "kilosort.run_kilosort: Computing preprocessing variables.\n",
      "kilosort.run_kilosort: Computing preprocessing variables.\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: N samples: 2028544\n",
      "kilosort.run_kilosort: N samples: 2028544\n",
      "kilosort.run_kilosort: N samples: 2028544\n",
      "kilosort.run_kilosort: N samples: 2028544\n",
      "kilosort.run_kilosort: N samples: 2028544\n",
      "kilosort.run_kilosort: N seconds: 67.61813333333333\n",
      "kilosort.run_kilosort: N seconds: 67.61813333333333\n",
      "kilosort.run_kilosort: N seconds: 67.61813333333333\n",
      "kilosort.run_kilosort: N seconds: 67.61813333333333\n",
      "kilosort.run_kilosort: N seconds: 67.61813333333333\n",
      "kilosort.run_kilosort: N batches: 34\n",
      "kilosort.run_kilosort: N batches: 34\n",
      "kilosort.run_kilosort: N batches: 34\n",
      "kilosort.run_kilosort: N batches: 34\n",
      "kilosort.run_kilosort: N batches: 34\n",
      "kilosort.run_kilosort: Preprocessing filters computed in  0.34s; total  0.35s\n",
      "kilosort.run_kilosort: Preprocessing filters computed in  0.34s; total  0.35s\n",
      "kilosort.run_kilosort: Preprocessing filters computed in  0.34s; total  0.35s\n",
      "kilosort.run_kilosort: Preprocessing filters computed in  0.34s; total  0.35s\n",
      "kilosort.run_kilosort: Preprocessing filters computed in  0.34s; total  0.35s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Computing drift correction.\n",
      "kilosort.run_kilosort: Computing drift correction.\n",
      "kilosort.run_kilosort: Computing drift correction.\n",
      "kilosort.run_kilosort: Computing drift correction.\n",
      "kilosort.run_kilosort: Computing drift correction.\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.spikedetect: Re-computing universal templates from data.\n",
      "kilosort.spikedetect: Re-computing universal templates from data.\n",
      "kilosort.spikedetect: Re-computing universal templates from data.\n",
      "kilosort.spikedetect: Re-computing universal templates from data.\n",
      "kilosort.spikedetect: Re-computing universal templates from data.\n",
      "100%|| 34/34 [00:14<00:00,  2.29it/s]\n",
      "kilosort.run_kilosort: drift computed in  15.73s; total  16.08s\n",
      "kilosort.run_kilosort: drift computed in  15.73s; total  16.08s\n",
      "kilosort.run_kilosort: drift computed in  15.73s; total  16.08s\n",
      "kilosort.run_kilosort: drift computed in  15.73s; total  16.08s\n",
      "kilosort.run_kilosort: drift computed in  15.73s; total  16.08s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Extracting spikes using templates\n",
      "kilosort.run_kilosort: Extracting spikes using templates\n",
      "kilosort.run_kilosort: Extracting spikes using templates\n",
      "kilosort.run_kilosort: Extracting spikes using templates\n",
      "kilosort.run_kilosort: Extracting spikes using templates\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.spikedetect: Re-computing universal templates from data.\n",
      "kilosort.spikedetect: Re-computing universal templates from data.\n",
      "kilosort.spikedetect: Re-computing universal templates from data.\n",
      "kilosort.spikedetect: Re-computing universal templates from data.\n",
      "kilosort.spikedetect: Re-computing universal templates from data.\n",
      "100%|| 34/34 [00:14<00:00,  2.31it/s]\n",
      "kilosort.run_kilosort: 92352 spikes extracted in  15.42s; total  31.55s\n",
      "kilosort.run_kilosort: 92352 spikes extracted in  15.42s; total  31.55s\n",
      "kilosort.run_kilosort: 92352 spikes extracted in  15.42s; total  31.55s\n",
      "kilosort.run_kilosort: 92352 spikes extracted in  15.42s; total  31.55s\n",
      "kilosort.run_kilosort: 92352 spikes extracted in  15.42s; total  31.55s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: First clustering\n",
      "kilosort.run_kilosort: First clustering\n",
      "kilosort.run_kilosort: First clustering\n",
      "kilosort.run_kilosort: First clustering\n",
      "kilosort.run_kilosort: First clustering\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "100%|| 8/8 [00:15<00:00,  1.92s/it]\n",
      "kilosort.run_kilosort: 161 clusters found, in  15.69s; total  47.24s\n",
      "kilosort.run_kilosort: 161 clusters found, in  15.69s; total  47.24s\n",
      "kilosort.run_kilosort: 161 clusters found, in  15.69s; total  47.24s\n",
      "kilosort.run_kilosort: 161 clusters found, in  15.69s; total  47.24s\n",
      "kilosort.run_kilosort: 161 clusters found, in  15.69s; total  47.24s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Extracting spikes using cluster waveforms\n",
      "kilosort.run_kilosort: Extracting spikes using cluster waveforms\n",
      "kilosort.run_kilosort: Extracting spikes using cluster waveforms\n",
      "kilosort.run_kilosort: Extracting spikes using cluster waveforms\n",
      "kilosort.run_kilosort: Extracting spikes using cluster waveforms\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "100%|| 34/34 [00:10<00:00,  3.14it/s]\n",
      "kilosort.run_kilosort: 34457 spikes extracted in  10.87s; total  58.11s\n",
      "kilosort.run_kilosort: 34457 spikes extracted in  10.87s; total  58.11s\n",
      "kilosort.run_kilosort: 34457 spikes extracted in  10.87s; total  58.11s\n",
      "kilosort.run_kilosort: 34457 spikes extracted in  10.87s; total  58.11s\n",
      "kilosort.run_kilosort: 34457 spikes extracted in  10.87s; total  58.11s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Final clustering\n",
      "kilosort.run_kilosort: Final clustering\n",
      "kilosort.run_kilosort: Final clustering\n",
      "kilosort.run_kilosort: Final clustering\n",
      "kilosort.run_kilosort: Final clustering\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "100%|| 8/8 [00:07<00:00,  1.03it/s]\n",
      "kilosort.run_kilosort: 75 clusters found, in  7.81s; total  65.93s\n",
      "kilosort.run_kilosort: 75 clusters found, in  7.81s; total  65.93s\n",
      "kilosort.run_kilosort: 75 clusters found, in  7.81s; total  65.93s\n",
      "kilosort.run_kilosort: 75 clusters found, in  7.81s; total  65.93s\n",
      "kilosort.run_kilosort: 75 clusters found, in  7.81s; total  65.93s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Merging clusters\n",
      "kilosort.run_kilosort: Merging clusters\n",
      "kilosort.run_kilosort: Merging clusters\n",
      "kilosort.run_kilosort: Merging clusters\n",
      "kilosort.run_kilosort: Merging clusters\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: 75 units found, in  0.07s; total  66.01s\n",
      "kilosort.run_kilosort: 75 units found, in  0.07s; total  66.01s\n",
      "kilosort.run_kilosort: 75 units found, in  0.07s; total  66.01s\n",
      "kilosort.run_kilosort: 75 units found, in  0.07s; total  66.01s\n",
      "kilosort.run_kilosort: 75 units found, in  0.07s; total  66.01s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Saving to phy and computing refractory periods\n",
      "kilosort.run_kilosort: Saving to phy and computing refractory periods\n",
      "kilosort.run_kilosort: Saving to phy and computing refractory periods\n",
      "kilosort.run_kilosort: Saving to phy and computing refractory periods\n",
      "kilosort.run_kilosort: Saving to phy and computing refractory periods\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: 4 units found with good refractory periods\n",
      "kilosort.run_kilosort: 4 units found with good refractory periods\n",
      "kilosort.run_kilosort: 4 units found with good refractory periods\n",
      "kilosort.run_kilosort: 4 units found with good refractory periods\n",
      "kilosort.run_kilosort: 4 units found with good refractory periods\n",
      "kilosort.run_kilosort: Total runtime: 66.67s = 00:01:7 h:m:s\n",
      "kilosort.run_kilosort: Total runtime: 66.67s = 00:01:7 h:m:s\n",
      "kilosort.run_kilosort: Total runtime: 66.67s = 00:01:7 h:m:s\n",
      "kilosort.run_kilosort: Total runtime: 66.67s = 00:01:7 h:m:s\n",
      "kilosort.run_kilosort: Total runtime: 66.67s = 00:01:7 h:m:s\n",
      "kilosort.run_kilosort: Sorting output saved in: Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um\\kilosort4.\n",
      "kilosort.run_kilosort: Sorting output saved in: Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um\\kilosort4.\n",
      "kilosort.run_kilosort: Sorting output saved in: Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um\\kilosort4.\n",
      "kilosort.run_kilosort: Sorting output saved in: Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um\\kilosort4.\n",
      "kilosort.run_kilosort: Sorting output saved in: Z:\\BrainPatch\\20241002\\lateral\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um\\kilosort4.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'n_chan_bin': 64,\n",
       "  'fs': 30000,\n",
       "  'batch_size': 60000,\n",
       "  'nblocks': 1,\n",
       "  'Th_universal': 9,\n",
       "  'Th_learned': 8,\n",
       "  'tmin': 0,\n",
       "  'tmax': inf,\n",
       "  'nt': 61,\n",
       "  'shift': None,\n",
       "  'scale': None,\n",
       "  'artifact_threshold': inf,\n",
       "  'nskip': 25,\n",
       "  'whitening_range': 32,\n",
       "  'highpass_cutoff': 300,\n",
       "  'binning_depth': 5,\n",
       "  'sig_interp': 20,\n",
       "  'drift_smoothing': [0.5, 0.5, 0.5],\n",
       "  'nt0min': 20,\n",
       "  'dmin': 50.0,\n",
       "  'dminx': 32,\n",
       "  'min_template_size': 10,\n",
       "  'template_sizes': 5,\n",
       "  'nearest_chans': 1,\n",
       "  'nearest_templates': 100,\n",
       "  'max_channel_distance': 50.0,\n",
       "  'templates_from_data': True,\n",
       "  'n_templates': 6,\n",
       "  'n_pcs': 6,\n",
       "  'Th_single_ch': 6,\n",
       "  'acg_threshold': 0.2,\n",
       "  'ccg_threshold': 0.25,\n",
       "  'cluster_downsampling': 20,\n",
       "  'x_centers': None,\n",
       "  'duplicate_spike_ms': 0.25,\n",
       "  'filename': WindowsPath('Z:/BrainPatch/20241002/lateral/Crimson__2024-10-02_12-21-01__20mA_2ms_400um/sig_eraasr.npy'),\n",
       "  'probe_name': 'Z:\\\\BrainPatch\\\\20241002\\\\64-4shank-poly-brainpatch-chanMap.mat',\n",
       "  'data_dtype': 'float32',\n",
       "  'data_dir': WindowsPath('Z:/BrainPatch/20241002/lateral/Crimson__2024-10-02_12-21-01__20mA_2ms_400um'),\n",
       "  'settings': {'n_chan_bin': 64,\n",
       "   'fs': 30000,\n",
       "   'batch_size': 60000,\n",
       "   'nblocks': 1,\n",
       "   'Th_universal': 9,\n",
       "   'Th_learned': 8,\n",
       "   'tmin': 0,\n",
       "   'tmax': inf,\n",
       "   'nt': 61,\n",
       "   'shift': None,\n",
       "   'scale': None,\n",
       "   'artifact_threshold': inf,\n",
       "   'nskip': 25,\n",
       "   'whitening_range': 32,\n",
       "   'highpass_cutoff': 300,\n",
       "   'binning_depth': 5,\n",
       "   'sig_interp': 20,\n",
       "   'drift_smoothing': [0.5, 0.5, 0.5],\n",
       "   'nt0min': 20,\n",
       "   'dmin': None,\n",
       "   'dminx': 32,\n",
       "   'min_template_size': 10,\n",
       "   'template_sizes': 5,\n",
       "   'nearest_chans': 1,\n",
       "   'nearest_templates': 100,\n",
       "   'max_channel_distance': None,\n",
       "   'templates_from_data': True,\n",
       "   'n_templates': 6,\n",
       "   'n_pcs': 6,\n",
       "   'Th_single_ch': 6,\n",
       "   'acg_threshold': 0.2,\n",
       "   'ccg_threshold': 0.25,\n",
       "   'cluster_downsampling': 20,\n",
       "   'x_centers': None,\n",
       "   'duplicate_spike_ms': 0.25,\n",
       "   'filename': 'Z:\\\\BrainPatch\\\\20241002\\\\lateral\\\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um\\\\sig_eraasr.npy',\n",
       "   'probe_name': 'Z:\\\\BrainPatch\\\\20241002\\\\64-4shank-poly-brainpatch-chanMap.mat',\n",
       "   'data_dtype': 'float32',\n",
       "   'data_dir': 'Z:\\\\BrainPatch\\\\20241002\\\\lateral\\\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um',\n",
       "   'settings': {...},\n",
       "   'probe': {'xc': array([500., 500., 500., 500., 500., 500., 500., 500., 500., 500., 500.,\n",
       "           750., 500., 750., 500., 750., 500., 750., 500., 750., 750., 750.,\n",
       "           500., 750., 750., 750., 750., 750., 750., 750., 750., 750.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.,   0., 250.,   0.,   0.,   0.,\n",
       "           250.,   0., 250.,   0., 250.,   0., 250.,   0., 250.,   0., 250.,\n",
       "           250., 250., 250., 250., 250., 250., 250., 250., 250.],\n",
       "          dtype=float32),\n",
       "    'yc': array([  0., 250., 200., 350., 150., 450.,  50., 400., 100., 600., 300.,\n",
       "           750., 500., 550., 700., 350., 650., 700., 550., 100., 500., 600.,\n",
       "           750.,  50., 300., 400., 250., 200.,   0., 450., 150., 650., 100.,\n",
       "           600.,  50., 400., 200., 250., 350., 450., 700.,   0., 550., 650.,\n",
       "           500., 150., 600., 750., 750., 300., 550., 500., 350., 700., 150.,\n",
       "           650.,   0., 450., 100., 400., 250., 300.,  50., 200.],\n",
       "          dtype=float32),\n",
       "    'kcoords': array([3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 4., 3., 4., 3., 4., 3.,\n",
       "           4., 3., 4., 4., 4., 3., 4., 4., 4., 4., 4., 4., 4., 4., 4., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 2., 1., 2., 1., 2., 1., 2.,\n",
       "           1., 2., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.], dtype=float32),\n",
       "    'chanMap': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "           17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "           34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "           51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]),\n",
       "    'n_chan': 64},\n",
       "   'do_CAR': True,\n",
       "   'invert_sign': False,\n",
       "   'NTbuff': 60122,\n",
       "   'Nchan': 64,\n",
       "   'duplicate_spike_bins': 7,\n",
       "   'torch_device': 'cuda',\n",
       "   'save_preprocessed_copy': False,\n",
       "   'results_dir': 'Z:\\\\BrainPatch\\\\20241002\\\\lateral\\\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um\\\\kilosort4'},\n",
       "  'probe': {'xc': array([500., 500., 500., 500., 500., 500., 500., 500., 500., 500., 500.,\n",
       "          750., 500., 750., 500., 750., 500., 750., 500., 750., 750., 750.,\n",
       "          500., 750., 750., 750., 750., 750., 750., 750., 750., 750.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0., 250.,   0.,   0.,   0.,\n",
       "          250.,   0., 250.,   0., 250.,   0., 250.,   0., 250.,   0., 250.,\n",
       "          250., 250., 250., 250., 250., 250., 250., 250., 250.],\n",
       "         dtype=float32),\n",
       "   'yc': array([  0., 250., 200., 350., 150., 450.,  50., 400., 100., 600., 300.,\n",
       "          750., 500., 550., 700., 350., 650., 700., 550., 100., 500., 600.,\n",
       "          750.,  50., 300., 400., 250., 200.,   0., 450., 150., 650., 100.,\n",
       "          600.,  50., 400., 200., 250., 350., 450., 700.,   0., 550., 650.,\n",
       "          500., 150., 600., 750., 750., 300., 550., 500., 350., 700., 150.,\n",
       "          650.,   0., 450., 100., 400., 250., 300.,  50., 200.],\n",
       "         dtype=float32),\n",
       "   'kcoords': array([3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 4., 3., 4., 3., 4., 3.,\n",
       "          4., 3., 4., 4., 4., 3., 4., 4., 4., 4., 4., 4., 4., 4., 4., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 2., 1., 2., 1., 2., 1., 2.,\n",
       "          1., 2., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.], dtype=float32),\n",
       "   'chanMap': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "          17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "          34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "          51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]),\n",
       "   'n_chan': 64},\n",
       "  'do_CAR': True,\n",
       "  'invert_sign': False,\n",
       "  'NTbuff': 60122,\n",
       "  'Nchan': 64,\n",
       "  'duplicate_spike_bins': 7,\n",
       "  'torch_device': 'cuda',\n",
       "  'save_preprocessed_copy': False,\n",
       "  'xc': array([500., 500., 500., 500., 500., 500., 500., 500., 500., 500., 500.,\n",
       "         750., 500., 750., 500., 750., 500., 750., 500., 750., 750., 750.,\n",
       "         500., 750., 750., 750., 750., 750., 750., 750., 750., 750.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0., 250.,   0.,   0.,   0.,\n",
       "         250.,   0., 250.,   0., 250.,   0., 250.,   0., 250.,   0., 250.,\n",
       "         250., 250., 250., 250., 250., 250., 250., 250., 250.],\n",
       "        dtype=float32),\n",
       "  'yc': array([  0., 250., 200., 350., 150., 450.,  50., 400., 100., 600., 300.,\n",
       "         750., 500., 550., 700., 350., 650., 700., 550., 100., 500., 600.,\n",
       "         750.,  50., 300., 400., 250., 200.,   0., 450., 150., 650., 100.,\n",
       "         600.,  50., 400., 200., 250., 350., 450., 700.,   0., 550., 650.,\n",
       "         500., 150., 600., 750., 750., 300., 550., 500., 350., 700., 150.,\n",
       "         650.,   0., 450., 100., 400., 250., 300.,  50., 200.],\n",
       "        dtype=float32),\n",
       "  'kcoords': array([3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 4., 3., 4., 3., 4., 3.,\n",
       "         4., 3., 4., 4., 4., 3., 4., 4., 4., 4., 4., 4., 4., 4., 4., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 2., 1., 2., 1., 2., 1., 2.,\n",
       "         1., 2., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.], dtype=float32),\n",
       "  'chanMap': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "         17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "         34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "         51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]),\n",
       "  'n_chan': 64,\n",
       "  'Nbatches': 34,\n",
       "  'preprocessing': {'whiten_mat': tensor([[ 1.3614e-01,  1.5751e-03,  4.8014e-03,  ...,  3.0415e-03,\n",
       "             8.0181e-03,  3.6528e-03],\n",
       "           [ 8.8735e-04,  1.3390e-01, -9.7157e-03,  ..., -4.1462e-04,\n",
       "             3.0313e-03,  3.3434e-04],\n",
       "           [ 4.2308e-03, -9.6126e-03,  1.4604e-01,  ..., -2.9698e-04,\n",
       "             2.9059e-03, -8.1227e-05],\n",
       "           ...,\n",
       "           [ 0.0000e+00, -4.1998e-04, -3.0021e-04,  ...,  1.6599e-01,\n",
       "             1.0078e-03, -7.5962e-03],\n",
       "           [ 8.4313e-03,  3.4808e-03,  4.4364e-03,  ...,  3.6358e-03,\n",
       "             1.5532e-01,  3.9459e-03],\n",
       "           [ 3.8432e-03,  7.9839e-04,  7.9402e-04,  ..., -5.6960e-03,\n",
       "             3.9459e-03,  1.7143e-01]], device='cuda:0'),\n",
       "   'hp_filter': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')},\n",
       "  'Wrot': tensor([[ 1.3614e-01,  1.5751e-03,  4.8014e-03,  ...,  3.0415e-03,\n",
       "            8.0181e-03,  3.6528e-03],\n",
       "          [ 8.8735e-04,  1.3390e-01, -9.7157e-03,  ..., -4.1462e-04,\n",
       "            3.0313e-03,  3.3434e-04],\n",
       "          [ 4.2308e-03, -9.6126e-03,  1.4604e-01,  ..., -2.9698e-04,\n",
       "            2.9059e-03, -8.1227e-05],\n",
       "          ...,\n",
       "          [ 0.0000e+00, -4.1998e-04, -3.0021e-04,  ...,  1.6599e-01,\n",
       "            1.0078e-03, -7.5962e-03],\n",
       "          [ 8.4313e-03,  3.4808e-03,  4.4364e-03,  ...,  3.6358e-03,\n",
       "            1.5532e-01,  3.9459e-03],\n",
       "          [ 3.8432e-03,  7.9839e-04,  7.9402e-04,  ..., -5.6960e-03,\n",
       "            3.9459e-03,  1.7143e-01]], device='cuda:0'),\n",
       "  'fwav': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       "  'wPCA': tensor([[-3.1412e-02, -2.8507e-02, -3.6966e-02, -3.4516e-02, -3.2431e-02,\n",
       "           -2.8595e-02, -2.3256e-02, -2.7555e-02, -3.4692e-02, -3.5799e-02,\n",
       "           -3.5886e-02, -4.1303e-02, -3.8910e-02, -3.3051e-02, -4.2171e-02,\n",
       "           -5.4464e-02, -7.7256e-02, -1.3836e-01, -1.4668e-01,  3.4317e-01,\n",
       "            7.4346e-01,  4.3674e-01,  1.3344e-01,  8.3346e-02,  9.0227e-02,\n",
       "            6.2426e-02,  3.5834e-02,  1.9543e-02,  1.0554e-02,  1.8943e-03,\n",
       "           -6.4639e-03, -2.0085e-02, -2.5142e-02, -3.0199e-02, -3.0398e-02,\n",
       "           -4.2350e-02, -4.3996e-02, -4.7566e-02, -5.4309e-02, -5.4093e-02,\n",
       "           -4.6105e-02, -4.1811e-02, -4.2534e-02, -4.7739e-02, -4.3248e-02,\n",
       "           -3.5234e-02, -3.3973e-02, -3.7266e-02, -2.4999e-02, -1.8936e-02,\n",
       "           -2.1974e-02, -2.5829e-02, -2.5675e-02, -2.5476e-02, -1.5532e-02,\n",
       "           -1.5114e-02, -1.5546e-02, -1.7706e-02, -1.0538e-02, -1.2172e-02,\n",
       "           -9.1085e-03],\n",
       "          [-6.8088e-02, -8.9777e-02, -9.1788e-02, -1.0906e-01, -1.3045e-01,\n",
       "           -1.1621e-01, -1.1468e-01, -1.3250e-01, -1.2107e-01, -9.8165e-02,\n",
       "           -1.0004e-01, -1.0046e-01, -8.1139e-02, -7.5939e-02, -5.0156e-02,\n",
       "           -7.2291e-03,  5.1688e-02,  2.3727e-01,  4.5277e-01,  1.4602e-01,\n",
       "           -1.9041e-01,  3.7192e-02,  2.7771e-01,  2.8928e-01,  2.3803e-01,\n",
       "            2.2510e-01,  2.2431e-01,  1.6703e-01,  1.4219e-01,  1.2733e-01,\n",
       "            1.1828e-01,  1.0312e-01,  8.9355e-02,  9.0035e-02,  6.7490e-02,\n",
       "            3.7828e-02,  3.2439e-03,  1.3701e-02,  1.0849e-02, -6.3016e-03,\n",
       "            1.0180e-03, -1.8097e-02, -3.1037e-02, -4.3072e-02, -4.0275e-02,\n",
       "           -6.0284e-02, -8.2672e-02, -8.8445e-02, -7.9222e-02, -9.0146e-02,\n",
       "           -8.6587e-02, -8.1272e-02, -7.0136e-02, -6.6094e-02, -7.2382e-02,\n",
       "           -8.5815e-02, -7.8741e-02, -6.3929e-02, -6.2929e-02, -6.0179e-02,\n",
       "           -4.8495e-02],\n",
       "          [ 2.6777e-02,  1.6669e-02, -1.0363e-02, -1.7041e-02, -3.0444e-02,\n",
       "           -3.0598e-02,  6.6821e-03,  2.7076e-03, -2.1139e-03, -4.6984e-03,\n",
       "            1.6020e-02,  5.3265e-02,  6.2787e-02,  6.1661e-02,  1.0586e-01,\n",
       "            1.7836e-01,  1.4416e-01,  1.4438e-01,  3.5141e-01,  6.0097e-01,\n",
       "            2.1238e-03, -2.6366e-01, -8.2213e-02,  2.8530e-02, -1.8078e-02,\n",
       "           -7.1838e-02, -1.1398e-01, -1.2249e-01, -1.0323e-01, -1.4242e-01,\n",
       "           -1.8391e-01, -1.8664e-01, -1.7243e-01, -1.6153e-01, -1.5988e-01,\n",
       "           -1.5827e-01, -1.5653e-01, -1.4511e-01, -8.7316e-02, -4.6200e-02,\n",
       "           -4.9875e-02, -2.6527e-02,  1.3385e-02,  5.2528e-03, -4.0183e-03,\n",
       "            4.5762e-02,  5.5174e-02,  4.0076e-02,  4.5456e-02,  5.5865e-02,\n",
       "            3.5660e-02,  5.6094e-02,  7.3689e-02,  7.5162e-02,  4.8009e-02,\n",
       "            3.9687e-02,  3.7227e-02,  1.5309e-02,  3.6982e-02,  6.3466e-02,\n",
       "            5.3518e-02],\n",
       "          [ 1.9635e-02,  5.7610e-02,  6.3413e-02,  4.4670e-03,  9.6603e-03,\n",
       "           -1.7757e-02, -1.6397e-02, -2.9225e-02, -5.2318e-03, -1.1318e-02,\n",
       "           -6.9504e-02, -1.0047e-01, -1.0139e-01, -1.4501e-01, -2.0087e-01,\n",
       "           -2.0022e-01, -2.3400e-01, -3.1228e-01, -7.9961e-02,  4.8845e-01,\n",
       "           -2.3118e-02, -3.7089e-01, -1.9775e-01, -5.4026e-02, -3.2157e-02,\n",
       "           -1.1066e-02, -5.5843e-03, -1.2946e-02,  3.4191e-02,  8.0576e-02,\n",
       "            7.1866e-02,  6.5218e-02,  9.6429e-02,  1.2265e-01,  1.6399e-01,\n",
       "            1.8123e-01,  1.7464e-01,  1.2732e-01,  1.1420e-01,  1.2849e-01,\n",
       "            1.0324e-01,  6.3965e-02,  5.9193e-02,  8.3284e-02,  1.0043e-01,\n",
       "            6.2936e-02,  1.9186e-02,  1.5632e-02,  1.0646e-02, -1.8983e-02,\n",
       "           -2.2307e-03,  1.7480e-02, -1.8458e-04, -6.0721e-02, -1.0658e-01,\n",
       "           -1.1060e-01, -7.6000e-02, -9.9129e-02, -1.2926e-01, -7.7388e-02,\n",
       "           -3.9314e-02],\n",
       "          [-9.7520e-02, -1.1282e-01, -1.4199e-01, -1.7953e-01, -1.9656e-01,\n",
       "           -1.4503e-01, -9.4413e-02, -6.8413e-02, -3.0799e-03,  1.2898e-01,\n",
       "            1.2830e-01,  1.3832e-01,  2.2503e-01,  2.9788e-01,  2.7333e-01,\n",
       "            1.7591e-01,  1.1996e-01,  3.9730e-02, -4.0213e-02,  4.6613e-02,\n",
       "            8.6978e-02,  1.8127e-02, -7.0874e-02, -1.0785e-01, -1.3193e-01,\n",
       "           -9.1408e-02, -9.1107e-02, -1.2037e-01, -1.0986e-01, -5.1919e-02,\n",
       "            2.6432e-02,  2.9303e-02,  4.6803e-02,  9.4442e-02,  1.1442e-01,\n",
       "            1.2100e-01,  3.1128e-02,  3.9677e-02,  1.1013e-01,  1.4904e-01,\n",
       "            1.5206e-01,  1.9710e-01,  1.5056e-01,  1.1164e-01,  4.7670e-02,\n",
       "           -9.1690e-02, -1.8840e-01, -1.7252e-01, -1.5720e-01, -1.4883e-01,\n",
       "           -1.5403e-01, -1.6024e-01, -1.4715e-01, -1.6235e-01, -1.5405e-01,\n",
       "           -1.1936e-01, -7.1837e-02, -7.9344e-02, -4.8539e-02,  4.0103e-03,\n",
       "            2.8605e-02],\n",
       "          [-5.7726e-02, -8.3891e-02, -7.7199e-02, -5.7624e-02, -5.5768e-02,\n",
       "           -4.1126e-03, -1.3923e-02, -1.8253e-02, -4.1912e-03,  3.9181e-02,\n",
       "            4.6151e-02,  2.8189e-02,  6.3953e-02,  1.0676e-01,  1.1608e-01,\n",
       "            3.2954e-02, -6.6920e-02, -1.5991e-01, -1.3698e-01,  1.4051e-01,\n",
       "           -2.3915e-02, -2.3451e-01, -1.9141e-01, -8.7427e-02,  2.0562e-03,\n",
       "            6.0200e-02,  1.6153e-01,  1.9781e-01,  1.1254e-01,  1.2983e-01,\n",
       "            1.3013e-01,  1.5402e-01,  8.6041e-02,  7.8217e-02,  6.2990e-02,\n",
       "            2.9640e-02, -3.4739e-02, -6.2302e-02, -1.2122e-01, -1.2840e-01,\n",
       "           -1.5881e-01, -1.2039e-01, -1.3198e-01, -1.8464e-01, -2.2425e-01,\n",
       "           -2.1819e-01, -1.7418e-01, -1.7449e-01, -1.6174e-01, -9.3095e-02,\n",
       "           -9.0253e-02, -2.3341e-02,  5.8072e-02,  1.6771e-01,  2.0964e-01,\n",
       "            1.9857e-01,  2.0986e-01,  2.4693e-01,  2.1733e-01,  1.2986e-01,\n",
       "            5.1894e-02]], device='cuda:0'),\n",
       "  'wTEMP': tensor([[ 2.2892e-02,  5.7103e-03,  1.7565e-02, -3.9904e-03, -1.6057e-02,\n",
       "           -5.6195e-03, -9.0460e-03, -1.5019e-02,  1.3822e-02,  2.2451e-02,\n",
       "           -4.1800e-03,  1.1552e-02,  2.2088e-02,  2.5431e-02,  5.4355e-02,\n",
       "            8.4416e-02,  8.4883e-02,  1.4960e-01,  3.0079e-01, -9.9919e-02,\n",
       "           -7.5142e-01, -4.9610e-01, -1.0640e-01, -2.6351e-02, -5.2855e-02,\n",
       "           -2.9857e-02, -8.7611e-03, -1.4185e-02, -1.2007e-03,  1.4624e-02,\n",
       "            1.1909e-02,  1.0480e-02,  2.0146e-02,  4.1107e-02,  4.9794e-02,\n",
       "            4.3291e-02,  3.1239e-02,  3.2854e-02,  4.5441e-02,  6.2792e-02,\n",
       "            6.4228e-02,  5.3062e-02,  5.2652e-02,  4.5936e-02,  2.2822e-02,\n",
       "            6.2804e-03, -1.1734e-02, -2.0464e-03, -2.0604e-03, -1.1530e-02,\n",
       "           -7.7428e-03, -3.4799e-03,  8.6669e-03,  1.3362e-02, -3.0348e-03,\n",
       "           -1.3746e-02, -1.8210e-02, -1.7752e-02, -7.3215e-03,  2.0870e-02,\n",
       "            1.9751e-02],\n",
       "          [-2.3196e-03,  2.4754e-02,  2.7154e-02,  3.3868e-03, -2.6932e-03,\n",
       "           -3.5527e-04,  1.2469e-02,  2.7086e-02,  1.9063e-02,  2.1999e-02,\n",
       "            2.2290e-02,  3.7000e-03,  6.8118e-03, -1.3950e-02, -3.7844e-02,\n",
       "           -3.6872e-02, -1.2052e-02,  6.5804e-02,  1.1246e-01, -3.1571e-01,\n",
       "           -7.3584e-01, -4.5175e-01, -1.1329e-01, -4.2459e-02, -4.8213e-02,\n",
       "           -1.3407e-02,  1.8544e-02,  3.2262e-02,  4.2698e-02,  5.7395e-02,\n",
       "            5.5347e-02,  6.7989e-02,  7.5629e-02,  9.0048e-02,  8.6636e-02,\n",
       "            9.8260e-02,  9.2829e-02,  8.8767e-02,  7.0289e-02,  7.0332e-02,\n",
       "            5.5889e-02,  2.9132e-02,  2.3332e-02,  5.1057e-02,  7.4780e-02,\n",
       "            6.6727e-02,  5.7318e-02,  5.7401e-02,  3.7649e-02,  3.1651e-02,\n",
       "            4.9407e-02,  5.4328e-02,  4.3576e-02,  1.2037e-02, -1.8930e-02,\n",
       "           -3.9007e-02, -2.8701e-02, -1.3129e-02, -3.6154e-02, -4.9238e-02,\n",
       "           -4.5779e-02],\n",
       "          [ 4.7450e-02,  5.9336e-02,  7.4065e-02,  8.1070e-02,  8.7283e-02,\n",
       "            8.7671e-02,  9.3291e-02,  9.8652e-02,  1.1011e-01,  9.7080e-02,\n",
       "            8.3895e-02,  8.4155e-02,  8.6923e-02,  8.7852e-02,  8.2471e-02,\n",
       "            5.0787e-02, -9.9933e-05, -8.9588e-02, -2.0130e-01, -3.2920e-01,\n",
       "           -4.2408e-01, -3.5660e-01, -2.8775e-01, -2.6328e-01, -2.4128e-01,\n",
       "           -2.1292e-01, -1.9145e-01, -1.4771e-01, -1.1744e-01, -9.4304e-02,\n",
       "           -8.1411e-02, -6.2451e-02, -4.8767e-02, -2.0767e-02,  4.4424e-03,\n",
       "            2.1890e-02,  3.3694e-02,  3.5085e-02,  3.4623e-02,  4.7905e-02,\n",
       "            4.7914e-02,  5.3035e-02,  4.7472e-02,  6.0338e-02,  6.0538e-02,\n",
       "            5.3583e-02,  5.5084e-02,  6.1971e-02,  5.5796e-02,  5.6365e-02,\n",
       "            6.4454e-02,  6.5197e-02,  5.8629e-02,  6.1607e-02,  6.2705e-02,\n",
       "            6.8997e-02,  6.4833e-02,  5.2885e-02,  4.5575e-02,  4.8207e-02,\n",
       "            3.4886e-02],\n",
       "          [-5.3762e-02, -3.2748e-02, -6.7087e-02, -6.9807e-02, -7.3013e-02,\n",
       "           -5.8776e-02, -3.9627e-02, -4.6657e-02, -3.5688e-02, -7.1668e-02,\n",
       "           -8.6906e-02, -7.9676e-02, -3.2094e-02, -1.2661e-03,  1.3065e-02,\n",
       "            3.4535e-02,  8.5032e-02,  1.4650e-01,  1.8326e-01,  3.7418e-01,\n",
       "            6.1949e-01,  4.0844e-01,  2.4562e-01,  1.9561e-01,  1.3132e-01,\n",
       "            3.8375e-02, -4.0253e-04, -3.4572e-02, -3.4647e-02, -4.6943e-02,\n",
       "           -4.3254e-02, -5.6545e-02, -9.3954e-02, -4.3040e-02, -6.4686e-02,\n",
       "           -5.4132e-02, -7.2659e-02, -4.8279e-02, -6.8164e-02, -7.7604e-02,\n",
       "           -5.2517e-02, -3.6261e-02, -3.1771e-02, -3.8154e-02, -3.0645e-02,\n",
       "           -5.3494e-02, -5.1408e-02, -5.8151e-02, -3.5328e-02, -4.1528e-02,\n",
       "           -7.0459e-02, -4.5001e-02, -3.0913e-02, -3.9496e-02,  2.9916e-02,\n",
       "            6.1619e-02, -6.4878e-04, -1.7931e-02,  1.0671e-02, -2.1577e-02,\n",
       "           -3.2581e-02],\n",
       "          [ 3.9798e-02,  4.2356e-02,  3.6818e-02,  4.4366e-02,  4.8589e-02,\n",
       "            3.1830e-02,  2.7185e-02,  2.9409e-02,  2.7936e-02,  3.6914e-02,\n",
       "            5.6916e-02,  6.1227e-02,  5.5089e-02,  5.1267e-02,  6.3805e-02,\n",
       "            8.3783e-02,  1.1362e-01,  1.8297e-01,  1.7849e-01, -2.6888e-01,\n",
       "           -6.9380e-01, -4.5439e-01, -1.6507e-01, -1.0574e-01, -1.1121e-01,\n",
       "           -9.4343e-02, -7.9146e-02, -5.6481e-02, -4.0303e-02, -4.3162e-02,\n",
       "           -3.6832e-02, -1.4507e-02, -4.9125e-03, -1.0223e-02, -2.5281e-02,\n",
       "           -7.8950e-03,  1.7014e-03,  1.3869e-02,  3.6330e-02,  3.3282e-02,\n",
       "            1.5041e-02,  2.5409e-02,  4.9694e-02,  6.1238e-02,  6.0226e-02,\n",
       "            5.9455e-02,  6.6643e-02,  7.0645e-02,  5.6139e-02,  5.0284e-02,\n",
       "            2.9110e-02,  4.0774e-02,  5.4242e-02,  5.6131e-02,  3.4087e-02,\n",
       "            3.7420e-02,  4.3707e-02,  4.1321e-02,  2.8048e-02,  2.8602e-02,\n",
       "            2.5429e-02],\n",
       "          [ 3.0893e-02,  1.5328e-02,  3.3695e-02,  4.4411e-02,  4.3293e-02,\n",
       "            3.8107e-02,  1.9519e-02,  2.7963e-02,  3.6120e-02,  2.6307e-02,\n",
       "            2.6767e-02,  3.7723e-02,  2.8941e-02,  2.2579e-02,  3.6346e-02,\n",
       "            4.6575e-02,  9.5412e-02,  1.7607e-01,  1.1596e-01, -5.2348e-01,\n",
       "           -7.2651e-01, -2.9489e-01, -4.6375e-02, -4.3657e-02, -5.1754e-02,\n",
       "           -2.6427e-02,  3.1468e-03,  1.8167e-02,  1.1539e-02,  1.4586e-02,\n",
       "            3.4442e-02,  4.8504e-02,  3.9057e-02,  3.5570e-02,  3.6246e-02,\n",
       "            5.4680e-02,  5.5563e-02,  6.0840e-02,  6.0000e-02,  4.5437e-02,\n",
       "            4.3763e-02,  4.2923e-02,  2.8081e-02,  2.0254e-02,  1.3905e-02,\n",
       "            4.9546e-03,  1.1226e-02,  1.0198e-02, -1.0228e-03, -9.7610e-03,\n",
       "            1.1887e-03, -2.2821e-03, -1.3505e-02, -1.2709e-03,  1.6993e-02,\n",
       "            3.1427e-02,  2.1753e-02,  2.4492e-02,  2.2258e-02,  9.7160e-03,\n",
       "            5.9204e-03]], device='cuda:0'),\n",
       "  'yup': array([  0.,  25.,  50.,  75., 100., 125., 150., 175., 200., 225., 250.,\n",
       "         275., 300., 325., 350., 375., 400., 425., 450., 475., 500., 525.,\n",
       "         550., 575., 600., 625., 650., 675., 700., 725., 750.,   0.,  25.,\n",
       "          50.,  75., 100., 125., 150., 175., 200., 225., 250., 275., 300.,\n",
       "         325., 350., 375., 400., 425., 450., 475., 500., 525., 550., 575.,\n",
       "         600., 625., 650., 675., 700., 725., 750.,   0.,  25.,  50.,  75.,\n",
       "         100., 125., 150., 175., 200., 225., 250., 275., 300., 325., 350.,\n",
       "         375., 400., 425., 450., 475., 500., 525., 550., 575., 600., 625.,\n",
       "         650., 675., 700., 725., 750.,   0.,  25.,  50.,  75., 100., 125.,\n",
       "         150., 175., 200., 225., 250., 275., 300., 325., 350., 375., 400.,\n",
       "         425., 450., 475., 500., 525., 550., 575., 600., 625., 650., 675.,\n",
       "         700., 725., 750.]),\n",
       "  'xup': array([  0., 250., 500., 750.]),\n",
       "  'ycup': array([  0.,  25.,  50.,  75., 100., 125., 150., 175., 200., 225., 250.,\n",
       "         275., 300., 325., 350., 375., 400., 425., 450., 475., 500., 525.,\n",
       "         550., 575., 600., 625., 650., 675., 700., 725., 750.,   0.,  25.,\n",
       "          50.,  75., 100., 125., 150., 175., 200., 225., 250., 275., 300.,\n",
       "         325., 350., 375., 400., 425., 450., 475., 500., 525., 550., 575.,\n",
       "         600., 625., 650., 675., 700., 725., 750.,   0.,  25.,  50.,  75.,\n",
       "         100., 125., 150., 175., 200., 225., 250., 275., 300., 325., 350.,\n",
       "         375., 400., 425., 450., 475., 500., 525., 550., 575., 600., 625.,\n",
       "         650., 675., 700., 725., 750.,   0.,  25.,  50.,  75., 100., 125.,\n",
       "         150., 175., 200., 225., 250., 275., 300., 325., 350., 375., 400.,\n",
       "         425., 450., 475., 500., 525., 550., 575., 600., 625., 650., 675.,\n",
       "         700., 725., 750.,   0.,  25.,  50.,  75., 100., 125., 150., 175.,\n",
       "         200., 225., 250., 275., 300., 325., 350., 375., 400., 425., 450.,\n",
       "         475., 500., 525., 550., 575., 600., 625., 650., 675., 700., 725.,\n",
       "         750.,   0.,  25.,  50.,  75., 100., 125., 150., 175., 200., 225.,\n",
       "         250., 275., 300., 325., 350., 375., 400., 425., 450., 475., 500.,\n",
       "         525., 550., 575., 600., 625., 650., 675., 700., 725., 750.,   0.,\n",
       "          25.,  50.,  75., 100., 125., 150., 175., 200., 225., 250., 275.,\n",
       "         300., 325., 350., 375., 400., 425., 450., 475., 500., 525., 550.,\n",
       "         575., 600., 625., 650., 675., 700., 725., 750.,   0.,  25.,  50.,\n",
       "          75., 100., 125., 150., 175., 200., 225., 250., 275., 300., 325.,\n",
       "         350., 375., 400., 425., 450., 475., 500., 525., 550., 575., 600.,\n",
       "         625., 650., 675., 700., 725., 750.,   0.,  25.,  50.,  75., 100.,\n",
       "         125., 150., 175., 200., 225., 250., 275., 300., 325., 350., 375.,\n",
       "         400., 425., 450., 475., 500., 525., 550., 575., 600., 625., 650.,\n",
       "         675., 700., 725., 750.,   0.,  25.,  50.,  75., 100., 125., 150.,\n",
       "         175., 200., 225., 250., 275., 300., 325., 350., 375., 400., 425.,\n",
       "         450., 475., 500., 525., 550., 575., 600., 625., 650., 675., 700.,\n",
       "         725., 750.,   0.,  25.,  50.,  75., 100., 125., 150., 175., 200.,\n",
       "         225., 250., 275., 300., 325., 350., 375., 400., 425., 450., 475.,\n",
       "         500., 525., 550., 575., 600., 625., 650., 675., 700., 725., 750.,\n",
       "           0.,  25.,  50.,  75., 100., 125., 150., 175., 200., 225., 250.,\n",
       "         275., 300., 325., 350., 375., 400., 425., 450., 475., 500., 525.,\n",
       "         550., 575., 600., 625., 650., 675., 700., 725., 750.,   0.,  25.,\n",
       "          50.,  75., 100., 125., 150., 175., 200., 225., 250., 275., 300.,\n",
       "         325., 350., 375., 400., 425., 450., 475., 500., 525., 550., 575.,\n",
       "         600., 625., 650., 675., 700., 725., 750.,   0.,  25.,  50.,  75.,\n",
       "         100., 125., 150., 175., 200., 225., 250., 275., 300., 325., 350.,\n",
       "         375., 400., 425., 450., 475., 500., 525., 550., 575., 600., 625.,\n",
       "         650., 675., 700., 725., 750.,   0.,  25.,  50.,  75., 100., 125.,\n",
       "         150., 175., 200., 225., 250., 275., 300., 325., 350., 375., 400.,\n",
       "         425., 450., 475., 500., 525., 550., 575., 600., 625., 650., 675.,\n",
       "         700., 725., 750.,   0.,  25.,  50.,  75., 100., 125., 150., 175.,\n",
       "         200., 225., 250., 275., 300., 325., 350., 375., 400., 425., 450.,\n",
       "         475., 500., 525., 550., 575., 600., 625., 650., 675., 700., 725.,\n",
       "         750.]),\n",
       "  'xcup': array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0., 250., 250., 250., 250., 250., 250., 250., 250.,\n",
       "         250., 250., 250., 250., 250., 250., 250., 250., 250., 250., 250.,\n",
       "         250., 250., 250., 250., 250., 250., 250., 250., 250., 250., 250.,\n",
       "         250., 250., 250., 250., 250., 250., 250., 250., 250., 250., 250.,\n",
       "         250., 250., 250., 250., 250., 250., 250., 250., 250., 250., 250.,\n",
       "         250., 250., 250., 250., 250., 250., 250., 250., 250., 250., 250.,\n",
       "         250., 250., 250., 250., 250., 250., 250., 250., 250., 250., 250.,\n",
       "         250., 250., 250., 250., 250., 250., 250., 250., 250., 250., 250.,\n",
       "         250., 250., 250., 250., 250., 250., 250., 250., 250., 250., 250.,\n",
       "         250., 250., 250., 250., 250., 250., 250., 250., 250., 250., 250.,\n",
       "         250., 250., 250., 250., 250., 250., 250., 250., 250., 250., 250.,\n",
       "         250., 250., 250., 250., 250., 250., 500., 500., 500., 500., 500.,\n",
       "         500., 500., 500., 500., 500., 500., 500., 500., 500., 500., 500.,\n",
       "         500., 500., 500., 500., 500., 500., 500., 500., 500., 500., 500.,\n",
       "         500., 500., 500., 500., 500., 500., 500., 500., 500., 500., 500.,\n",
       "         500., 500., 500., 500., 500., 500., 500., 500., 500., 500., 500.,\n",
       "         500., 500., 500., 500., 500., 500., 500., 500., 500., 500., 500.,\n",
       "         500., 500., 500., 500., 500., 500., 500., 500., 500., 500., 500.,\n",
       "         500., 500., 500., 500., 500., 500., 500., 500., 500., 500., 500.,\n",
       "         500., 500., 500., 500., 500., 500., 500., 500., 500., 500., 500.,\n",
       "         500., 500., 500., 500., 500., 500., 500., 500., 500., 500., 500.,\n",
       "         500., 500., 500., 500., 500., 500., 500., 500., 500., 500., 500.,\n",
       "         500., 500., 500., 500., 500., 500., 500., 500., 500., 750., 750.,\n",
       "         750., 750., 750., 750., 750., 750., 750., 750., 750., 750., 750.,\n",
       "         750., 750., 750., 750., 750., 750., 750., 750., 750., 750., 750.,\n",
       "         750., 750., 750., 750., 750., 750., 750., 750., 750., 750., 750.,\n",
       "         750., 750., 750., 750., 750., 750., 750., 750., 750., 750., 750.,\n",
       "         750., 750., 750., 750., 750., 750., 750., 750., 750., 750., 750.,\n",
       "         750., 750., 750., 750., 750., 750., 750., 750., 750., 750., 750.,\n",
       "         750., 750., 750., 750., 750., 750., 750., 750., 750., 750., 750.,\n",
       "         750., 750., 750., 750., 750., 750., 750., 750., 750., 750., 750.,\n",
       "         750., 750., 750., 750., 750., 750., 750., 750., 750., 750., 750.,\n",
       "         750., 750., 750., 750., 750., 750., 750., 750., 750., 750., 750.,\n",
       "         750., 750., 750., 750., 750., 750., 750., 750., 750., 750., 750.,\n",
       "         750.]),\n",
       "  'iC': tensor([[41, 34, 34, 34, 32, 45, 45, 45, 36, 36, 37, 37, 49, 38, 38, 38, 35, 35,\n",
       "           39, 51, 51, 42, 42, 42, 33, 33, 43, 43, 53, 53, 47, 41, 34, 34, 34, 32,\n",
       "           45, 45, 45, 36, 36, 37, 37, 49, 38, 38, 38, 35, 35, 39, 51, 51, 42, 42,\n",
       "           42, 33, 33, 43, 43, 53, 53, 47, 41, 34, 34, 34, 32, 45, 45, 45, 36, 36,\n",
       "           37, 37, 49, 38, 38, 38, 35, 35, 39, 51, 51, 42, 42, 42, 33, 33, 43, 43,\n",
       "           53, 53, 47, 41, 34, 34, 34, 32, 45, 45, 45, 36, 36, 37, 37, 49, 38, 38,\n",
       "           38, 35, 35, 39, 51, 51, 42, 42, 42, 33, 33, 43, 43, 53, 53, 47, 56, 56,\n",
       "           62, 58, 58, 54, 54, 63, 63, 63, 60, 60, 61, 52, 52, 52, 59, 57, 57, 44,\n",
       "           44, 44, 50, 46, 46, 46, 55, 40, 40, 40, 48, 56, 56, 62, 58, 58, 54, 54,\n",
       "           63, 63, 63, 60, 60, 61, 52, 52, 52, 59, 57, 57, 44, 44, 44, 50, 46, 46,\n",
       "           46, 55, 40, 40, 40, 48, 56, 56, 62, 58, 58, 54, 54, 63, 63, 63, 60, 60,\n",
       "           61, 52, 52, 52, 59, 57, 57, 44, 44, 44, 50, 46, 46, 46, 55, 40, 40, 40,\n",
       "           48, 56, 56, 62, 58, 58, 54, 54, 63, 63, 63, 60, 60, 61, 52, 52, 52, 59,\n",
       "           57, 57, 44, 44, 44, 50, 46, 46, 46, 55, 40, 40, 40, 48,  0,  0,  6,  8,\n",
       "            8,  4,  4,  2,  2,  1,  1,  1, 10, 10,  3,  3,  7,  5,  5,  5, 12, 18,\n",
       "           18,  9,  9,  9, 16, 16, 14, 14, 22,  0,  0,  6,  8,  8,  4,  4,  2,  2,\n",
       "            1,  1,  1, 10, 10,  3,  3,  7,  5,  5,  5, 12, 18, 18,  9,  9,  9, 16,\n",
       "           16, 14, 14, 22,  0,  0,  6,  8,  8,  4,  4,  2,  2,  1,  1,  1, 10, 10,\n",
       "            3,  3,  7,  5,  5,  5, 12, 18, 18,  9,  9,  9, 16, 16, 14, 14, 22,  0,\n",
       "            0,  6,  8,  8,  4,  4,  2,  2,  1,  1,  1, 10, 10,  3,  3,  7,  5,  5,\n",
       "            5, 12, 18, 18,  9,  9,  9, 16, 16, 14, 14, 22, 28, 23, 23, 23, 19, 19,\n",
       "           30, 30, 27, 26, 26, 24, 24, 24, 15, 25, 25, 25, 29, 20, 20, 20, 13, 21,\n",
       "           21, 31, 31, 31, 17, 17, 11, 28, 23, 23, 23, 19, 19, 30, 30, 27, 26, 26,\n",
       "           24, 24, 24, 15, 25, 25, 25, 29, 20, 20, 20, 13, 21, 21, 31, 31, 31, 17,\n",
       "           17, 11, 28, 23, 23, 23, 19, 19, 30, 30, 27, 26, 26, 24, 24, 24, 15, 25,\n",
       "           25, 25, 29, 20, 20, 20, 13, 21, 21, 31, 31, 31, 17, 17, 11, 28, 23, 23,\n",
       "           23, 19, 19, 30, 30, 27, 26, 26, 24, 24, 24, 15, 25, 25, 25, 29, 20, 20,\n",
       "           20, 13, 21, 21, 31, 31, 31, 17, 17, 11]], device='cuda:0'),\n",
       "  'iC2': tensor([[  0,  94,   2,  ..., 493, 494, 495],\n",
       "          [ 62,   1,  33,  ..., 462, 463, 433],\n",
       "          [ 31,  32,  64,  ..., 431, 432, 402],\n",
       "          ...,\n",
       "          [107,  76, 226,  ..., 300, 419, 419],\n",
       "          [ 45,  45, 195,  ..., 269, 450, 388],\n",
       "          [ 76,  14, 164,  ..., 331, 388, 450]], device='cuda:0'),\n",
       "  'weigh': tensor([[[1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:0'),\n",
       "  'yblk': array([374.]),\n",
       "  'dshift': array([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]),\n",
       "  'iKxx': tensor([[ 9.9198e-01, -1.5480e-07,  3.5587e-06,  ..., -7.3708e-43,\n",
       "            4.9872e-36, -3.9798e-40],\n",
       "          [-1.5480e-07,  9.9387e-01, -4.3317e-02,  ...,  4.9965e-36,\n",
       "           -3.9872e-40,  4.9965e-36],\n",
       "          [ 3.5586e-06, -4.3317e-02,  9.9387e-01,  ..., -2.1514e-37,\n",
       "            9.2622e-39, -1.1580e-34],\n",
       "          ...,\n",
       "          [-7.3568e-43,  4.9965e-36, -2.1514e-37,  ...,  9.9387e-01,\n",
       "           -1.5509e-07,  1.8843e-03],\n",
       "          [ 4.9872e-36, -3.9872e-40,  9.2622e-39,  ..., -1.5509e-07,\n",
       "            9.9386e-01, -8.1964e-05],\n",
       "          [-3.9798e-40,  4.9965e-36, -1.1580e-34,  ...,  1.8843e-03,\n",
       "           -8.1964e-05,  9.9387e-01]], device='cuda:0'),\n",
       "  'iCC': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "           18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "           36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "           54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:0'),\n",
       "  'iU': tensor([34, 34, 34, 41, 41, 56,  0,  6,  0,  0,  0, 23, 28, 28, 23, 45, 54,  4,\n",
       "           4,  2, 19, 19, 37, 37, 37, 37, 37, 37, 37, 60,  2,  2,  1,  1, 27, 38,\n",
       "          49, 38, 38, 49, 38, 38, 38, 49, 49, 38, 52,  3, 10, 10, 10, 10,  3, 24,\n",
       "          39, 35, 39, 39, 51, 35, 35, 35, 35, 44, 44, 57, 57, 44,  5, 25, 42, 42,\n",
       "          42, 42, 42, 42, 42, 42, 51, 44, 44, 44, 44, 44, 44, 44, 44, 44, 50, 12,\n",
       "          33, 33, 43, 43, 33, 33, 43, 43, 33, 46, 46, 40, 55, 55, 46,  9, 31, 31,\n",
       "          47, 53, 47, 53, 48, 14, 11, 17, 17, 17, 11, 17], device='cuda:0'),\n",
       "  'runtime': 66.6658251285553},\n",
       " array([[3.20000000e+01, 1.02000000e+02, 1.18394732e+00],\n",
       "        [3.40000000e+01, 1.01000000e+02, 9.43524122e-01],\n",
       "        [4.69000000e+02, 4.00000000e+01, 6.34997129e-01],\n",
       "        ...,\n",
       "        [2.02825700e+06, 1.03000000e+02, 8.79594982e-01],\n",
       "        [2.02828800e+06, 5.20000000e+01, 9.24855351e-01],\n",
       "        [2.02835500e+06, 6.70000000e+01, 7.52419829e-01]]),\n",
       " array([60, 69, 25, ..., 61, 33, 50]),\n",
       " tensor([[[-12.0706,  -9.5545,  -0.9351,   0.7791,   0.9714,   2.9280]],\n",
       " \n",
       "         [[ -7.3978, -10.8530,   1.1381,   0.6749,  -3.5919,   2.9373]],\n",
       " \n",
       "         [[ -4.6428,  -5.5229,  -8.4564,   9.7893,   4.2176,  -5.6924]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[  3.1864,   9.3434,  -0.3804,   0.9668,  -2.9013,   3.0372]],\n",
       " \n",
       "         [[ -9.6967,  -0.6661,  -1.6266,  -1.6401,   0.9113,   0.6040]],\n",
       " \n",
       "         [[  4.7111,   8.2418,  -0.1032,  -1.4185,   0.7310,   0.2956]]]),\n",
       " tensor([[[0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.]]]),\n",
       " array([[0.9999994 , 0.52052975, 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.5205297 , 0.9999996 , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.99999964, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.9999995 , 0.14143988,\n",
       "         0.22879922],\n",
       "        [0.        , 0.        , 0.        , ..., 0.14143988, 0.9999999 ,\n",
       "         0.46967745],\n",
       "        [0.        , 0.        , 0.        , ..., 0.22879922, 0.46967745,\n",
       "         0.9999995 ]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0.]),\n",
       " array([25.10496894, 26.80962733, 17.32748031, 13.06772908, 23.91320375,\n",
       "        13.79439252, 15.56924803, 23.34607143, 19.15803571, 25.81365384,\n",
       "        17.37589286, 23.80287356, 23.24677121,  1.78137652,  5.71428571,\n",
       "        14.78095238, 10.        ,  4.98876404, 25.52321644, 31.82245509,\n",
       "        26.66757246,  8.71153846,  0.        , 16.58353293,  9.03225806,\n",
       "         4.02797203,  3.33333333,  4.80406091, 25.65539267,  7.65217391,\n",
       "        26.73214285,  3.        ,  1.14624506,  2.01447178, 18.6102459 ,\n",
       "         0.        ,  3.63636364,  0.        , 21.25177453,  3.33333333,\n",
       "         0.        , 16.36613119,  3.70815451, 18.18519492,  0.        ,\n",
       "         0.        ,  7.08806818, 19.12577041,  3.36648531, 10.09935205,\n",
       "         6.56      ,  9.97101449,  2.07283382, 24.94999999,  9.15789474,\n",
       "         4.7761194 ,  4.25284091, 15.69492242, 15.80915916,  3.62558502,\n",
       "         9.47152847,  1.42857143,  7.93939394,  0.        ,  2.07916667,\n",
       "         2.50125313, 14.67831552, 13.33333333, 12.35619047, 17.80690741,\n",
       "         6.43870968, 15.35384615, 12.79487179,  0.        , 15.35384615]),\n",
       " array([ True,  True,  True, ...,  True,  True,  True]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'Z:\\\\BrainPatch\\\\20241002\\\\lateral\\\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um\\\\sig_eraasr.npy'\n",
    "np.save(filename, sig_eraasr.astype(np.float32))\n",
    "settings = {'filename':filename,\n",
    "            'probe_name':'Z:\\\\BrainPatch\\\\20241002\\\\64-4shank-poly-brainpatch-chanMap.mat',\n",
    "            'n_chan_bin':64,\n",
    "            'nearest_chans':1,\n",
    "            'data_dtype':'float32'}\n",
    "\n",
    "kilosort.run_kilosort(settings,  file_object=sig_eraasr.astype(np.float32), data_dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'rb') as fid: \n",
    "    templates = np.load('Z:\\\\BrainPatch\\\\20241002\\\\lateral\\\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um\\\\kilosort4\\\\templates.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spike times, template shape, and channel number\n",
    "spike_times = np.load('Z:\\\\BrainPatch\\\\20241002\\\\lateral\\\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um\\\\kilosort4\\\\spike_times.npy')\n",
    "chan_map = np.load('Z:\\\\BrainPatch\\\\20241002\\\\lateral\\\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um\\\\kilosort4\\\\channel_map.npy')\n",
    "templates = np.load('Z:\\\\BrainPatch\\\\20241002\\\\lateral\\\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um\\\\kilosort4\\\\templates.npy')\n",
    "st = np.load('Z:\\\\BrainPatch\\\\20241002\\\\lateral\\\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um\\\\kilosort4\\\\spike_templates.npy')\n",
    "\n",
    "# best channel for each template. Might change this to channel with greatest minimum value\n",
    "chan_best = (templates**2).sum(axis=1).argmax(axis=-1)\n",
    "chan_best = chan_map[chan_best]\n",
    "\n",
    "# channels of interest\n",
    "channels = [5, 17, 35, 37, 50, 51]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=len(channels), sharex=True, sharey=True)\n",
    "\n",
    "cmap = np.array(plt.colormaps.get_cmap('tab10').colors)\n",
    "\n",
    "for i_channel, channel in enumerate(channels):\n",
    "    ax[i_channel].plot(np.arange(sig_eraasr.shape[0])/30000, sig_eraasr[:,channel], label=channel)\n",
    "\n",
    "    chan_templates = np.nonzero(chan_best == channel)\n",
    "\n",
    "    for i_ct, ct in enumerate(chan_templates[0]):\n",
    "        ax[i_channel].vlines(spike_times[st == ct]/30000, sig_eraasr[:,channel].min(), sig_eraasr[:,channel].max(), color = cmap[i_ct+1, :], alpha=0.3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ax[i_channel].set_ylabel('magnitude (uV)')\n",
    "    ax[i_channel].set_title(channel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([44], dtype=int64),)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(chan_best == 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = np.load('Z:\\\\BrainPatch\\\\20241002\\\\lateral\\\\Crimson__2024-10-02_12-21-01__20mA_2ms_400um\\\\kilosort4\\\\spike_templates.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([60, 69, 25, 73, 50, 13, 49, 52, 32, 52])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_times"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainpatch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
