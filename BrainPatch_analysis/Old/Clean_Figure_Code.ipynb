{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BrainPatch Figure 3 Code\n",
    "\n",
    "Create the ephys portions of Figure\n",
    "\n",
    "\n",
    "## Import python packages\n",
    "All of these should be working properly if you've used the provided conda environment file for your OS. However, if there are any versioning issues just reach out to me on github @kb0dkin and we'll get it sorted out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openephys_utils # loading and basic processing code.\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Polygon # this is a nice way to show error bars and standard deviations\n",
    "\n",
    "# data analysis standards\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import os, glob, re\n",
    "\n",
    "# csv writing\n",
    "import csv\n",
    "\n",
    "# tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# open the plots with QT\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing and conversion\n",
    "\n",
    "First we have to take all of the raw data and process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local copy of the data\n",
    "base_dir = ''\n",
    "\n",
    "# probe and settings\n",
    "probe_name = ''\n",
    "settings = {'probe_name':probe_name,\n",
    "            'n_chan_bin':64,\n",
    "            'nearest_chans':0}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3g\n",
    "\n",
    "Example waveforms from the kilosort data. One from each channel. \n",
    "\n",
    "The example waveforms are from units that have a pre-stimulation mean firing rate of at least 0.5Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a per-channel index of the waveform from the FR dataframe\n",
    "# loaded from a csv\n",
    "wf_mapping = pd.read_csv()\n",
    "wf_mapping = {\n",
    "    41: 620, # could also be 211, 481, or 340\n",
    "    34: 208, # or 745\n",
    "    56: 113, # or 487\n",
    "    62: 751,\n",
    "    0: 350,\n",
    "    6: 220,\n",
    "    23: 120,\n",
    "    28: 358,\n",
    "    32: 232,\n",
    "    45: 20,\n",
    "    58: 363,\n",
    "    54: 236,\n",
    "    8: 370,\n",
    "    19: 243,\n",
    "    36:126, \n",
    "    37: 33,\n",
    "    63: 255,\n",
    "    1: 387,\n",
    "    2: 388,\n",
    "    26: None,\n",
    "    38: 524,\n",
    "    49: 786,\n",
    "    52: 526,\n",
    "    10: 149,\n",
    "    3: 538,\n",
    "    24: None,\n",
    "    35: 286,\n",
    "    39: 412,\n",
    "    57: 159,\n",
    "    49: 556,\n",
    "    5: 818, \n",
    "    25: None,\n",
    "    42: 569,\n",
    "    51: 689,\n",
    "    44: 570,\n",
    "    50: 306,\n",
    "    18: 76, # only exists in one recording, might toss\n",
    "    20: None,\n",
    "    43: 312,\n",
    "    33: 710,\n",
    "    46: 83,\n",
    "    9: None,\n",
    "    31: 192,\n",
    "    47: 457,\n",
    "    53: 195,\n",
    "    40: 464,\n",
    "    48: 868,\n",
    "    14: 739,\n",
    "    11: 335,\n",
    "    17: 338,\n",
    "    60: 383,\n",
    "    27: None,\n",
    "    61: 400,\n",
    "    29: None,\n",
    "    12: 576,\n",
    "    4: 239,\n",
    "    30: 373,\n",
    "    7: 422,\n",
    "    16: None,\n",
    "    15: None,\n",
    "    22: 736,\n",
    "}\n",
    "\n",
    "# Waveforms, laid out according to the probe mapping from NeuroNexus\n",
    "probe_grid = plt.GridSpec(16,4, wspace=.5, hspace=.7)\n",
    "\n",
    "fig_probe = plt.figure()\n",
    "\n",
    "ax_probe = dict()\n",
    "for i_channel, (channel,waveform) in enumerate(wf_dict.items()):\n",
    "    row = int(probe['yc'][channel]/50)\n",
    "    col = int(probe['kcoords'][channel]) - 1\n",
    "\n",
    "    ax_probe[channel] = fig_probe.add_subplot(probe_grid[row,col])\n",
    "    ax_probe[channel].plot(waveform)\n",
    "    ax_probe[channel].set_title(f'channel')\n",
    "    print(channel)\n",
    "\n",
    "    for spine in ax_probe[channel].spines:\n",
    "        ax_probe[channel].spines[spine].set_visible(False)\n",
    "\n",
    "    ax_probe[channel].set_xticks([])\n",
    "    ax_probe[channel].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3f ?\n",
    "firing rates vs current at different depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_dirs = ['Z://BrainPatch//20241002//lateral//',\n",
    "             'Z://BrainPatch//20240925//',\n",
    "             'Z:BrainPatch//20240821']\n",
    "\n",
    "# all 2ms stimulations at 400 um in the base_dirs\n",
    "directories = [os.path.join(base_dir,directory) for base_dir in base_dirs for directory in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir,directory)) and '2ms' in directory and '400um' in directory]\n",
    "\n",
    "# probe map\n",
    "probe_name = \"Z:\\\\BrainPatch\\\\20241002\\\\64-4shank-poly-brainpatch-chanMap.mat\"\n",
    "\n",
    "# settings for kilosort\n",
    "settings = {'probe_name':probe_name,\n",
    "            'n_chan_bin':64,\n",
    "            'nearest_chans':1}\n",
    "\n",
    "\n",
    "# have to define this somewhere -- probably in the utils\n",
    "FR_df = gimme_a_FR_df(directories, probe_name, settings) \n",
    "\n",
    "\n",
    "\n",
    "fig_amp_scatter, ax_amp_scatter = plt.subplots(nrows = 4, ncols=2, sharex=True, sharey=True)\n",
    "fig_amp_line, ax_amp_line = plt.subplots(nrows = 4, ncols = 2, sharex=True, sharey=True)\n",
    "\n",
    "fig_amp_line.set_size_inches(6, 10)\n",
    "\n",
    "fid_response = open('Z:\\\\BrainPatch\\\\Current_vs_responses_stim_responses.csv','w')\n",
    "fid_means = open('Z:\\\\BrainPatch\\\\Current_vs_responses_prestim_means.csv','w')\n",
    "\n",
    "for i_current, current in enumerate(FR_df['current'].unique()):\n",
    "    # first 2ms firing rate -- scatter\n",
    "    FR_df.loc[FR_df['current'].eq(current)].plot.scatter(ax = ax_amp_scatter[i_current, 1], x = 'poststim_first', y = 'depth', s=2)\n",
    "    ax_amp_scatter[i_current,1].set_title(f'{current} mA stimulation responses')\n",
    "    \n",
    "    # line plot of response mean and std \n",
    "    summary = FR_df.loc[FR_df['current'].eq(current)].groupby('depth')['poststim_first'].agg(['mean','std']) #.plot(ax = ax_amp_line[i_current, 1], x = 'mean', y='depth', xerr = 'std')\n",
    "    ax_amp_line[i_current, 1].plot(summary['mean'], summary.index)\n",
    "    ax_amp_line[i_current, 1].fill_betweenx(summary.index, np.maximum(summary['mean'] - summary['std'],0), summary['mean'] + summary['std'], alpha=0.2)\n",
    "    ax_amp_line[i_current,1].set_title(f'{current} mA stimulation responses')\n",
    "\n",
    "    # stim to csv\n",
    "    summary['current'] = current\n",
    "    summary.to_csv(fid_response, header=(i_current==0))\n",
    "\n",
    "\n",
    "    # pre-stimulation mean\n",
    "    FR_df.loc[FR_df['current'].eq(current)].plot.scatter(ax = ax_amp_scatter[i_current, 0], x = 'prestim_mean', y = 'depth', s=2)\n",
    "    ax_amp_scatter[i_current,0].set_title(f'{current} mA pre-stimulation means')\n",
    "    \n",
    "    # line plot of mean and std\n",
    "    summary = FR_df.loc[FR_df['current'].eq(current)].groupby('depth')['prestim_mean'].agg(['mean','std']) #.plot(ax = ax_amp_line[i_current, 1], x = 'mean', y='depth', xerr = 'std')\n",
    "    ax_amp_line[i_current, 0].plot(summary['mean'], summary.index)\n",
    "    ax_amp_line[i_current, 0].fill_betweenx(summary.index, np.maximum(summary['mean'] - summary['std'],0), summary['mean'] + summary['std'], alpha=0.2)\n",
    "    ax_amp_line[i_current,0].set_title(f'{current} mA pre-stimulation means')\n",
    "    ax_amp_line[i_current,0].set_ylabel('Depth $\\mu$m')\n",
    "\n",
    "    # stim to csv\n",
    "    summary['current'] = current\n",
    "    summary.to_csv(fid_means, header=(i_current==0))\n",
    "    \n",
    "    # remove the spines from the axes\n",
    "    for spine in ax_amp_line[i_current,0].spines:\n",
    "        ax_amp_line[i_current,0].spines[spine].set_visible(False)\n",
    "        ax_amp_line[i_current,1].spines[spine].set_visible(False)\n",
    "\n",
    "fid_means.close()\n",
    "fid_response.close()\n",
    "\n",
    "fig_amp_line.savefig('Z://BrainPatch//current_vs_response.svg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Figure \n",
    "This figure shows some of the preprocessing steps, and goes into the LFP responses at different distances.\n",
    "\n",
    "\n",
    "First, let's look at the artifacts that are produced solely by the LED/current source. This dataset is recorded from a mouse without ChrimsonR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'Z:\\\\BrainPatch\\\\Raw_Data\\\\Wildtype_Artifacts'\n",
    "\n",
    "fig_raw,ax_raw = plt.subplots()\n",
    "fig_eraasr,ax_eraasr = plt.subplots()\n",
    "\n",
    "# for the artifact\n",
    "csv_file_raw = open('Z:\\\\BrainPatch\\\\Figures\\\\Supplemental\\\\Artifacts_raw.csv', 'w')\n",
    "csv_writer_raw = csv.writer(csv_file_raw)\n",
    "csv_writer_raw.writerow(['current','','trace'])\n",
    "\n",
    "# errasr'd artifact\n",
    "csv_file_eraasr = open('Z:\\\\BrainPatch\\\\Figures\\\\Supplemental\\\\Artifacts_eraasr.csv', 'w')\n",
    "csv_writer_eraasr = csv.writer(csv_file_eraasr)\n",
    "csv_writer_eraasr.writerow(['current','','trace'])\n",
    "\n",
    "for i_directory,directory in enumerate([dd for dd in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir,dd))]):\n",
    "    # distance information from the directory name\n",
    "    distance = re.search('(\\d{4})um', directory)[0]\n",
    "\n",
    "    # load the data - previously loaded if available\n",
    "    sig, timestamps, stim, stim_ts = openephys_utils.open_sig_stims(os.path.join(base_dir,directory))\n",
    "    sig_eraasr = openephys_utils.ERAASR(sig, stim, save=False)\n",
    "\n",
    "    # plot the mean waveform for each stimulation distance\n",
    "    openephys_utils.plot_mean_LFP(sig, stim, channel = 45, pre_stim=1, ax=ax_raw, show_stim=i_directory==0, label=distance, len_ms = 10, align_stim=False)\n",
    "    openephys_utils.plot_mean_LFP(sig_eraasr, stim, channel = 45, pre_stim=1, ax=ax_eraasr, show_stim=i_directory==0, label=distance, len_ms = 10, align_stim=False)\n",
    "\n",
    "\n",
    "# get the traces and put them into the csv file\n",
    "for child in ax_raw.lines:\n",
    "    data = np.stack(child.get_data())\n",
    "    csv_writer_raw.writerow(data)\n",
    "    \n",
    "for child in ax_eraasr.lines:\n",
    "    data = np.stack(child.get_data())\n",
    "    csv_writer_eraasr.writerow(data)\n",
    "\n",
    "\n",
    "# clean up the plot\n",
    "ax_raw.legend() # add a plot\n",
    "ax_eraasr.legend()\n",
    "for spine in ax_raw.spines: # turn off the box around the axis\n",
    "    ax_raw.spines[spine].set_visible(False) \n",
    "    ax_eraasr.spines[spine].set_visible(False) \n",
    "\n",
    "ax_raw.set_xlabel('Time (ms)')\n",
    "ax_raw.set_ylabel('Voltage (mV)')\n",
    "ax_eraasr.set_xlabel('Time (ms)')\n",
    "ax_eraasr.set_ylabel('Voltage (mV)')\n",
    "\n",
    "ax_eraasr.set_ylim(ax_raw.get_ylim())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the LFP from a recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 recordings in Z:/BrainPatch/Raw_Data/20241002\n",
      "4 unique current values and 5 unique distances\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4fa13515624ec88e7ef3e16be3c148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20_400', '20_400', '15_400', '15_400', '10_400', '10_400', '5_400', '15_400', '5_600', '15_600', '20_600', '20_900', '15_900', '10_900', '5_900', '5_1200', '10_1200', '15_1200', '20_1200', '20_1500', '15_1500', '10_1500']\n"
     ]
    }
   ],
   "source": [
    "# plot it with openephys_utils\n",
    "openephys_utils.LFP_stim_bulk('Z:/BrainPatch/Raw_Data/20241002')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import collections\n",
    "\n",
    "# csv\n",
    "csv_file_min = open('Z:\\\\BrainPatch\\\\Figures\\\\Supplemental\\\\mean_response_min_time.csv', 'w')\n",
    "csv_writer_min = csv.writer(csv_file_min)\n",
    "csv_writer_min.writerow(['current','time', 'distance'])\n",
    "\n",
    "fig = plt.gcf()\n",
    "for ax in fig.get_axes():\n",
    "    ax_child = ax.get_children()\n",
    "    for child in ax_child:\n",
    "        if type(child) == collections.PathCollection:\n",
    "            offs = child.get_offsets().data\n",
    "            offs = np.append(offs, np.ones((offs.shape[0],1))*int(ax.get_title().strip(' mm')), axis=1)\n",
    "            csv_writer_min.writerows(offs)\n",
    "\n",
    "\n",
    "csv_file_min.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from matplotlib import collections\n",
    "\n",
    "# csv\n",
    "csv_file_min = open('Z:\\\\BrainPatch\\\\Figures\\\\Supplemental\\\\mean_response_min_depth.csv', 'w')\n",
    "csv_writer_min = csv.writer(csv_file_min)\n",
    "csv_writer_min.writerow(['magnitude','distance', 'current'])\n",
    "\n",
    "fig = plt.gcf()\n",
    "for ax in fig.get_axes():\n",
    "    ax_child = ax.get_children()\n",
    "    for child in ax_child:\n",
    "        if type(child) == collections.PathCollection:\n",
    "            offs = child.get_offsets().data\n",
    "            offs = np.append(offs, np.ones((offs.shape[0],1))*int(ax.get_title().strip(' mA')), axis=1)\n",
    "            csv_writer_min.writerows(offs)\n",
    "\n",
    "\n",
    "csv_file_min.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kilosort",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
